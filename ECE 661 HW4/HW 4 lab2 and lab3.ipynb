{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/googledrive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePv_k1ZF9tJt",
        "outputId": "7509f8b7-8958-4525-e027-fc26dfc1c5f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/googledrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/googledrive/MyDrive/ECE661_HW4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPFcFp-1DoLq",
        "outputId": "b45ed2b0-9ff8-456e-9b9f-61f276700eb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/googledrive/MyDrive/ECE661_HW4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z9oh5RDt63j",
        "outputId": "43bf212b-02d5-4e6a-d9c1-b25bbd880151"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t\t  net_after_finetune.pt\t\t        quantized_net_after_finetune.pt\n",
            " FP_layers.py\t  net_after_global_iterative_prune.pt   resnet20.py\n",
            "'hw4 (1).ipynb'   net_after_iterative_prune.pt\t        train_util.py\n",
            "'hw4 (2).ipynb'   pretrained_model.pt\t\t        Untitled0.ipynb\n",
            " LAB1.ipynb\t  __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "mIIWMKmbMSr0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFYobWdf8vQs"
      },
      "source": [
        "### Lab2 (a) Model preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "kVgBq1qd8vQx"
      },
      "outputs": [],
      "source": [
        "from resnet20 import ResNetCIFAR\n",
        "from train_util import train, finetune, test\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from FP_layers import *\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/googledrive/MyDrive/ECE661_HW4')"
      ],
      "metadata": {
        "id": "tWym_Bqa9neX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdOofcKxCNCw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "_ccNTKnU8vQ0"
      },
      "outputs": [],
      "source": [
        "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
        "net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dqszDrA8vQ1",
        "outputId": "33c550e4-4d15-4f69-9558-009fa3ed49fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3231, Test accuracy=0.9151\n"
          ]
        }
      ],
      "source": [
        "# Load the best weight paramters\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7GiJCTT8vQ2"
      },
      "source": [
        "### Lab2 (b) Prune by percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4S-HgSpB8vQ2"
      },
      "outputs": [],
      "source": [
        "def prune_by_percentage(layer, q=70.0):\n",
        "    \"\"\"\n",
        "    Pruning the weight paramters by threshold.\n",
        "    :param q: pruning percentile. 'q' percent of the least\n",
        "    significant weight parameters will be pruned.\n",
        "    \"\"\"\n",
        "    # Convert the weight of \"layer\" to numpy array\n",
        "    weights=layer.weight.data.cpu().numpy()\n",
        "\n",
        "    # Compute the q-th percentile of the abs of the converted array\n",
        "    threshold=np.percentile(np.abs(weights),q)\n",
        "\n",
        "    # Generate a binary mask same shape as weight to decide which element to prune\n",
        "    mask=np.abs(weights) >= threshold\n",
        "\n",
        "    # Convert mask to torch tensor and put on GPU\n",
        "    mask=torch.from_numpy(mask).float().to(device)\n",
        "\n",
        "    # Multiply the weight by mask to perform pruning\n",
        "    layer.weight.data *= mask\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBinRayL8vQ3",
        "outputId": "666774db-059c-4906-b688-da3b81f80048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning with q = 30\n",
            "Sparsity of head_conv.0.conv: 30.09%\n",
            "Sparsity of body_op.0.conv1.0.conv: 29.99%\n",
            "Sparsity of body_op.0.conv2.0.conv: 29.99%\n",
            "Sparsity of body_op.1.conv1.0.conv: 29.99%\n",
            "Sparsity of body_op.1.conv2.0.conv: 29.99%\n",
            "Sparsity of body_op.2.conv1.0.conv: 29.99%\n",
            "Sparsity of body_op.2.conv2.0.conv: 29.99%\n",
            "Sparsity of body_op.3.conv1.0.conv: 30.01%\n",
            "Sparsity of body_op.3.conv2.0.conv: 30.00%\n",
            "Sparsity of body_op.4.conv1.0.conv: 30.00%\n",
            "Sparsity of body_op.4.conv2.0.conv: 30.00%\n",
            "Sparsity of body_op.5.conv1.0.conv: 30.00%\n",
            "Sparsity of body_op.5.conv2.0.conv: 30.00%\n",
            "Sparsity of body_op.6.conv1.0.conv: 30.00%\n",
            "Sparsity of body_op.6.conv2.0.conv: 30.00%\n",
            "Sparsity of body_op.7.conv1.0.conv: 30.00%\n",
            "Sparsity of body_op.7.conv2.0.conv: 30.00%\n",
            "Sparsity of body_op.8.conv1.0.conv: 30.00%\n",
            "Sparsity of body_op.8.conv2.0.conv: 30.00%\n",
            "Sparsity of final_fc.linear: 30.00%\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3698, Test accuracy=0.9028\n",
            "Pruning with q = 50\n",
            "Sparsity of head_conv.0.conv: 50.00%\n",
            "Sparsity of body_op.0.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.0.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.1.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.1.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.2.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.2.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.3.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.3.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.4.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.4.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.5.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.5.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.6.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.6.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.7.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.7.conv2.0.conv: 50.00%\n",
            "Sparsity of body_op.8.conv1.0.conv: 50.00%\n",
            "Sparsity of body_op.8.conv2.0.conv: 50.00%\n",
            "Sparsity of final_fc.linear: 50.00%\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.6774, Test accuracy=0.8210\n",
            "Pruning with q = 70\n",
            "Sparsity of head_conv.0.conv: 69.91%\n",
            "Sparsity of body_op.0.conv1.0.conv: 70.01%\n",
            "Sparsity of body_op.0.conv2.0.conv: 70.01%\n",
            "Sparsity of body_op.1.conv1.0.conv: 70.01%\n",
            "Sparsity of body_op.1.conv2.0.conv: 70.01%\n",
            "Sparsity of body_op.2.conv1.0.conv: 70.01%\n",
            "Sparsity of body_op.2.conv2.0.conv: 70.01%\n",
            "Sparsity of body_op.3.conv1.0.conv: 69.99%\n",
            "Sparsity of body_op.3.conv2.0.conv: 70.00%\n",
            "Sparsity of body_op.4.conv1.0.conv: 70.00%\n",
            "Sparsity of body_op.4.conv2.0.conv: 70.00%\n",
            "Sparsity of body_op.5.conv1.0.conv: 70.00%\n",
            "Sparsity of body_op.5.conv2.0.conv: 70.00%\n",
            "Sparsity of body_op.6.conv1.0.conv: 70.00%\n",
            "Sparsity of body_op.6.conv2.0.conv: 70.00%\n",
            "Sparsity of body_op.7.conv1.0.conv: 70.00%\n",
            "Sparsity of body_op.7.conv2.0.conv: 70.00%\n",
            "Sparsity of body_op.8.conv1.0.conv: 70.00%\n",
            "Sparsity of body_op.8.conv2.0.conv: 70.00%\n",
            "Sparsity of final_fc.linear: 70.00%\n",
            "Files already downloaded and verified\n",
            "Test Loss=2.4417, Test accuracy=0.4204\n"
          ]
        }
      ],
      "source": [
        "q_values = [30, 50, 70]\n",
        "\n",
        "for q in q_values:\n",
        "    print(\"Pruning with q =\", q)\n",
        "    net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "\n",
        "    for name, layer in net.named_modules():\n",
        "        if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "            # Apply pruning by percentage\n",
        "            prune_by_percentage(layer, q=q)\n",
        "\n",
        "            # Count the number of zeros and total parameters for sparsity\n",
        "            np_weight = layer.weight.data.cpu().numpy()\n",
        "            zeros = np.sum(np_weight == 0)\n",
        "            total = np_weight.size\n",
        "\n",
        "            # Calculate and print sparsity\n",
        "            sparsity = zeros / total\n",
        "            print(f'Sparsity of {name}: {sparsity:.2%}')\n",
        "\n",
        "    # Test the pruned model\n",
        "    test(net)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtt1UHps8vQ4"
      },
      "source": [
        "### Lab2 (c) Finetune pruned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fU5zfIFr8vQ4"
      },
      "outputs": [],
      "source": [
        "def finetune_after_prune(net, trainloader, criterion, optimizer, prune=True):\n",
        "    \"\"\"\n",
        "    Finetune the pruned model for a single epoch\n",
        "    Make sure pruned weights are kept as zero\n",
        "    \"\"\"\n",
        "    # Build a dictionary for the nonzero weights\n",
        "    weight_mask = {}\n",
        "    for name,layer in net.named_modules():\n",
        "        if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "            # Your code here: generate a mask in GPU torch tensor to have 1 for nonzero element and 0 for zero element\n",
        "            weight_mask[name] = (layer.weight != 0).float().to(device)\n",
        "\n",
        "    global_steps = 0\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if prune:\n",
        "            for name,layer in net.named_modules():\n",
        "                if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "                    # Your code here: Use weight_mask to make sure zero elements remains zero\n",
        "                    layer.weight.data *= weight_mask[name]\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        global_steps += 1\n",
        "\n",
        "        if global_steps % 50 == 0:\n",
        "            end = time.time()\n",
        "            batch_size = 256\n",
        "            num_examples_per_second = 50 * batch_size / (end - start)\n",
        "            print(\"[Step=%d]\\tLoss=%.4f\\tacc=%.4f\\t%.1f examples/second\"\n",
        "                 % (global_steps, train_loss / (batch_idx + 1), (correct / total), num_examples_per_second))\n",
        "            start = time.time()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "As8w11oG8vQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1843deae-cd2a-4849-d367-0aa9e7bb75cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Get pruned model\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "for name,layer in net.named_modules():\n",
        "    if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "        prune_by_percentage(layer, q=70.0)\n",
        "\n",
        "# Training setup, do not change\n",
        "batch_size=256\n",
        "lr=0.002\n",
        "reg=1e-4\n",
        "\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=16)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.875, weight_decay=reg, nesterov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igUoi-GI8vQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ad7cf6-bdc1-424c-d08c-165832028595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.4122\tacc=0.8602\t1151.1 examples/second\n",
            "[Step=100]\tLoss=0.3620\tacc=0.8764\t2643.2 examples/second\n",
            "[Step=150]\tLoss=0.3306\tacc=0.8866\t1678.5 examples/second\n",
            "Test Loss=0.4251, Test acc=0.8682\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=50]\tLoss=0.2529\tacc=0.9120\t1179.3 examples/second\n",
            "[Step=100]\tLoss=0.2469\tacc=0.9143\t1514.4 examples/second\n",
            "[Step=150]\tLoss=0.2402\tacc=0.9163\t1803.8 examples/second\n",
            "Test Loss=0.3958, Test acc=0.8759\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=50]\tLoss=0.2197\tacc=0.9210\t1172.0 examples/second\n",
            "[Step=100]\tLoss=0.2149\tacc=0.9246\t2384.1 examples/second\n",
            "[Step=150]\tLoss=0.2120\tacc=0.9254\t1749.0 examples/second\n",
            "Test Loss=0.3800, Test acc=0.8800\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=50]\tLoss=0.1958\tacc=0.9306\t1148.7 examples/second\n",
            "[Step=100]\tLoss=0.1987\tacc=0.9297\t2347.9 examples/second\n",
            "[Step=150]\tLoss=0.1992\tacc=0.9297\t1909.6 examples/second\n",
            "Test Loss=0.3705, Test acc=0.8840\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=50]\tLoss=0.1901\tacc=0.9350\t1190.4 examples/second\n",
            "[Step=100]\tLoss=0.1883\tacc=0.9359\t2543.4 examples/second\n",
            "[Step=150]\tLoss=0.1901\tacc=0.9348\t2218.8 examples/second\n",
            "Test Loss=0.3649, Test acc=0.8845\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=50]\tLoss=0.1750\tacc=0.9375\t1317.4 examples/second\n",
            "[Step=100]\tLoss=0.1834\tacc=0.9352\t2138.7 examples/second\n",
            "[Step=150]\tLoss=0.1804\tacc=0.9371\t2369.8 examples/second\n",
            "Test Loss=0.3586, Test acc=0.8858\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "[Step=50]\tLoss=0.1736\tacc=0.9408\t1434.6 examples/second\n",
            "[Step=100]\tLoss=0.1767\tacc=0.9391\t1801.5 examples/second\n",
            "[Step=150]\tLoss=0.1778\tacc=0.9376\t2376.9 examples/second\n",
            "Test Loss=0.3543, Test acc=0.8871\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "[Step=50]\tLoss=0.1761\tacc=0.9382\t1524.8 examples/second\n",
            "[Step=100]\tLoss=0.1738\tacc=0.9389\t1772.0 examples/second\n",
            "[Step=150]\tLoss=0.1713\tacc=0.9399\t2460.7 examples/second\n",
            "Test Loss=0.3498, Test acc=0.8880\n",
            "Saving...\n",
            "\n",
            "Epoch: 8\n",
            "[Step=50]\tLoss=0.1635\tacc=0.9420\t1554.3 examples/second\n",
            "[Step=100]\tLoss=0.1649\tacc=0.9429\t1728.9 examples/second\n",
            "[Step=150]\tLoss=0.1663\tacc=0.9423\t2535.7 examples/second\n",
            "Test Loss=0.3494, Test acc=0.8883\n",
            "Saving...\n",
            "\n",
            "Epoch: 9\n",
            "[Step=50]\tLoss=0.1634\tacc=0.9445\t1274.9 examples/second\n",
            "[Step=100]\tLoss=0.1610\tacc=0.9443\t1989.1 examples/second\n",
            "[Step=150]\tLoss=0.1630\tacc=0.9434\t1956.7 examples/second\n",
            "Test Loss=0.3442, Test acc=0.8898\n",
            "Saving...\n",
            "\n",
            "Epoch: 10\n",
            "[Step=50]\tLoss=0.1562\tacc=0.9467\t1361.6 examples/second\n",
            "[Step=100]\tLoss=0.1619\tacc=0.9448\t2041.8 examples/second\n",
            "[Step=150]\tLoss=0.1585\tacc=0.9463\t2053.9 examples/second\n",
            "Test Loss=0.3439, Test acc=0.8896\n",
            "\n",
            "Epoch: 11\n",
            "[Step=50]\tLoss=0.1575\tacc=0.9454\t1297.8 examples/second\n",
            "[Step=100]\tLoss=0.1557\tacc=0.9450\t2230.1 examples/second\n",
            "[Step=150]\tLoss=0.1548\tacc=0.9457\t1907.1 examples/second\n",
            "Test Loss=0.3417, Test acc=0.8917\n",
            "Saving...\n",
            "\n",
            "Epoch: 12\n",
            "[Step=50]\tLoss=0.1601\tacc=0.9430\t1182.8 examples/second\n",
            "[Step=100]\tLoss=0.1592\tacc=0.9459\t2565.0 examples/second\n",
            "[Step=150]\tLoss=0.1564\tacc=0.9464\t1752.0 examples/second\n",
            "Test Loss=0.3413, Test acc=0.8915\n",
            "\n",
            "Epoch: 13\n",
            "[Step=50]\tLoss=0.1531\tacc=0.9450\t1193.8 examples/second\n",
            "[Step=100]\tLoss=0.1518\tacc=0.9471\t2518.0 examples/second\n",
            "[Step=150]\tLoss=0.1538\tacc=0.9467\t1987.6 examples/second\n",
            "Test Loss=0.3386, Test acc=0.8909\n",
            "\n",
            "Epoch: 14\n",
            "[Step=50]\tLoss=0.1530\tacc=0.9475\t1246.1 examples/second\n",
            "[Step=100]\tLoss=0.1493\tacc=0.9483\t2510.5 examples/second\n",
            "[Step=150]\tLoss=0.1488\tacc=0.9485\t2593.8 examples/second\n",
            "Test Loss=0.3381, Test acc=0.8933\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=50]\tLoss=0.1477\tacc=0.9493\t1574.0 examples/second\n",
            "[Step=100]\tLoss=0.1513\tacc=0.9490\t1851.2 examples/second\n",
            "[Step=150]\tLoss=0.1501\tacc=0.9493\t2658.2 examples/second\n",
            "Test Loss=0.3366, Test acc=0.8927\n",
            "\n",
            "Epoch: 16\n",
            "[Step=50]\tLoss=0.1494\tacc=0.9487\t1522.9 examples/second\n",
            "[Step=100]\tLoss=0.1476\tacc=0.9496\t1611.0 examples/second\n",
            "[Step=150]\tLoss=0.1467\tacc=0.9494\t1850.2 examples/second\n",
            "Test Loss=0.3366, Test acc=0.8939\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "[Step=50]\tLoss=0.1439\tacc=0.9501\t1403.1 examples/second\n",
            "[Step=100]\tLoss=0.1432\tacc=0.9503\t1991.1 examples/second\n",
            "[Step=150]\tLoss=0.1440\tacc=0.9497\t2218.3 examples/second\n",
            "Test Loss=0.3358, Test acc=0.8938\n",
            "\n",
            "Epoch: 18\n",
            "[Step=50]\tLoss=0.1427\tacc=0.9495\t1311.5 examples/second\n",
            "[Step=100]\tLoss=0.1397\tacc=0.9496\t2288.2 examples/second\n",
            "[Step=150]\tLoss=0.1422\tacc=0.9493\t1948.3 examples/second\n",
            "Test Loss=0.3335, Test acc=0.8956\n",
            "Saving...\n",
            "\n",
            "Epoch: 19\n",
            "[Step=50]\tLoss=0.1428\tacc=0.9493\t1176.1 examples/second\n",
            "[Step=100]\tLoss=0.1417\tacc=0.9500\t2592.8 examples/second\n",
            "[Step=150]\tLoss=0.1421\tacc=0.9497\t1763.1 examples/second\n",
            "Test Loss=0.3352, Test acc=0.8928\n"
          ]
        }
      ],
      "source": [
        "# Model finetuning\n",
        "for epoch in range(20):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    finetune_after_prune(net, trainloader, criterion, optimizer,prune=True)\n",
        "    #Start the testing code.\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    num_val_steps = len(testloader)\n",
        "    val_acc = correct / total\n",
        "    print(\"Test Loss=%.4f, Test acc=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        print(\"Saving...\")\n",
        "        torch.save(net.state_dict(), \"net_after_finetune.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SY9fOfwq8vQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8532b60d-59e1-4d0b-92b2-58310ae668dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of head_conv.0.conv: 0.6990740740740741\n",
            "Sparsity of body_op.0.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.0.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.1.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.1.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.2.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.2.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.3.conv1.0.conv: 0.6998697916666666\n",
            "Sparsity of body_op.3.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.4.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.4.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.5.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.5.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.6.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.6.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.7.conv1.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.7.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.8.conv1.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.8.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of final_fc.linear: 0.7\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3335, Test accuracy=0.8956\n"
          ]
        }
      ],
      "source": [
        "# Check sparsity of the finetuned model, make sure it's not changed\n",
        "net.load_state_dict(torch.load(\"net_after_finetune.pt\"))\n",
        "\n",
        "for name,layer in net.named_modules():\n",
        "    if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "        # Your code here:\n",
        "        # Convert the weight of \"layer\" to numpy array\n",
        "        np_weight = layer.weight.data.cpu().numpy()\n",
        "        # Count number of zeros\n",
        "        zeros = np.sum(np_weight == 0)\n",
        "        # Count number of parameters\n",
        "        total = np_weight.size\n",
        "        # Print sparsity\n",
        "        print('Sparsity of '+name+': '+str(zeros/total))\n",
        "\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT7FM9WZ8vQ6"
      },
      "source": [
        "### Lab2 (d) Iterative pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4wtdqnfr8vQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e348012d-2670-4124-a103-bc758d204d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.0472\tacc=0.9854\t1467.9 examples/second\n",
            "[Step=100]\tLoss=0.0471\tacc=0.9852\t2290.7 examples/second\n",
            "[Step=150]\tLoss=0.0481\tacc=0.9845\t2072.9 examples/second\n",
            "Test Loss=0.3260, Test acc=0.9151\n",
            "\n",
            "Epoch: 1\n",
            "[Step=50]\tLoss=0.0473\tacc=0.9858\t1272.5 examples/second\n",
            "[Step=100]\tLoss=0.0496\tacc=0.9839\t2673.8 examples/second\n",
            "[Step=150]\tLoss=0.0493\tacc=0.9842\t1936.9 examples/second\n",
            "Test Loss=0.3261, Test acc=0.9154\n",
            "\n",
            "Epoch: 2\n",
            "[Step=50]\tLoss=0.0502\tacc=0.9841\t1277.4 examples/second\n",
            "[Step=100]\tLoss=0.0490\tacc=0.9843\t2634.7 examples/second\n",
            "[Step=150]\tLoss=0.0509\tacc=0.9839\t2513.8 examples/second\n",
            "Test Loss=0.3252, Test acc=0.9150\n",
            "\n",
            "Epoch: 3\n",
            "[Step=50]\tLoss=0.0559\tacc=0.9806\t1441.3 examples/second\n",
            "[Step=100]\tLoss=0.0533\tacc=0.9822\t2072.6 examples/second\n",
            "[Step=150]\tLoss=0.0527\tacc=0.9830\t2613.5 examples/second\n",
            "Test Loss=0.3291, Test acc=0.9135\n",
            "\n",
            "Epoch: 4\n",
            "[Step=50]\tLoss=0.0611\tacc=0.9807\t1543.6 examples/second\n",
            "[Step=100]\tLoss=0.0622\tacc=0.9799\t1845.0 examples/second\n",
            "[Step=150]\tLoss=0.0620\tacc=0.9798\t2619.9 examples/second\n",
            "Test Loss=0.3370, Test acc=0.9107\n",
            "\n",
            "Epoch: 5\n",
            "[Step=50]\tLoss=0.0706\tacc=0.9744\t1520.2 examples/second\n",
            "[Step=100]\tLoss=0.0697\tacc=0.9751\t2079.4 examples/second\n",
            "[Step=150]\tLoss=0.0696\tacc=0.9748\t2323.8 examples/second\n",
            "Test Loss=0.3360, Test acc=0.9087\n",
            "\n",
            "Epoch: 6\n",
            "[Step=50]\tLoss=0.0907\tacc=0.9694\t1375.7 examples/second\n",
            "[Step=100]\tLoss=0.0862\tacc=0.9710\t2344.5 examples/second\n",
            "[Step=150]\tLoss=0.0861\tacc=0.9706\t1961.4 examples/second\n",
            "Test Loss=0.3339, Test acc=0.9066\n",
            "\n",
            "Epoch: 7\n",
            "[Step=50]\tLoss=0.1301\tacc=0.9544\t1276.0 examples/second\n",
            "[Step=100]\tLoss=0.1234\tacc=0.9577\t2524.2 examples/second\n",
            "[Step=150]\tLoss=0.1193\tacc=0.9591\t2009.2 examples/second\n",
            "Test Loss=0.3362, Test acc=0.9021\n",
            "\n",
            "Epoch: 8\n",
            "[Step=50]\tLoss=0.1647\tacc=0.9439\t1309.3 examples/second\n",
            "[Step=100]\tLoss=0.1591\tacc=0.9444\t2606.6 examples/second\n",
            "[Step=150]\tLoss=0.1545\tacc=0.9457\t2474.0 examples/second\n",
            "Test Loss=0.3458, Test acc=0.8953\n",
            "\n",
            "Epoch: 9\n",
            "[Step=50]\tLoss=0.2704\tacc=0.9062\t1513.7 examples/second\n",
            "[Step=100]\tLoss=0.2536\tacc=0.9128\t1918.6 examples/second\n",
            "[Step=150]\tLoss=0.2423\tacc=0.9158\t2519.2 examples/second\n",
            "Test Loss=0.3892, Test acc=0.8759\n",
            "\n",
            "Epoch: 10\n",
            "[Step=50]\tLoss=0.2026\tacc=0.9319\t1626.8 examples/second\n",
            "[Step=100]\tLoss=0.2064\tacc=0.9294\t1859.6 examples/second\n",
            "[Step=150]\tLoss=0.2058\tacc=0.9295\t2634.7 examples/second\n",
            "Test Loss=0.3720, Test acc=0.8811\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "[Step=50]\tLoss=0.2008\tacc=0.9313\t1587.3 examples/second\n",
            "[Step=100]\tLoss=0.1924\tacc=0.9332\t2126.8 examples/second\n",
            "[Step=150]\tLoss=0.1912\tacc=0.9334\t2218.9 examples/second\n",
            "Test Loss=0.3657, Test acc=0.8824\n",
            "Saving...\n",
            "\n",
            "Epoch: 12\n",
            "[Step=50]\tLoss=0.1852\tacc=0.9351\t1321.1 examples/second\n",
            "[Step=100]\tLoss=0.1823\tacc=0.9366\t2687.6 examples/second\n",
            "[Step=150]\tLoss=0.1813\tacc=0.9367\t1898.2 examples/second\n",
            "Test Loss=0.3598, Test acc=0.8845\n",
            "Saving...\n",
            "\n",
            "Epoch: 13\n",
            "[Step=50]\tLoss=0.1753\tacc=0.9383\t1240.2 examples/second\n",
            "[Step=100]\tLoss=0.1725\tacc=0.9393\t2671.8 examples/second\n",
            "[Step=150]\tLoss=0.1737\tacc=0.9403\t2141.0 examples/second\n",
            "Test Loss=0.3566, Test acc=0.8847\n",
            "Saving...\n",
            "\n",
            "Epoch: 14\n",
            "[Step=50]\tLoss=0.1767\tacc=0.9421\t1287.0 examples/second\n",
            "[Step=100]\tLoss=0.1773\tacc=0.9394\t2521.1 examples/second\n",
            "[Step=150]\tLoss=0.1726\tacc=0.9411\t2638.6 examples/second\n",
            "Test Loss=0.3518, Test acc=0.8873\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=50]\tLoss=0.1668\tacc=0.9418\t1558.7 examples/second\n",
            "[Step=100]\tLoss=0.1643\tacc=0.9434\t1905.7 examples/second\n",
            "[Step=150]\tLoss=0.1634\tacc=0.9436\t2692.0 examples/second\n",
            "Test Loss=0.3493, Test acc=0.8883\n",
            "Saving...\n",
            "\n",
            "Epoch: 16\n",
            "[Step=50]\tLoss=0.1656\tacc=0.9424\t1591.5 examples/second\n",
            "[Step=100]\tLoss=0.1590\tacc=0.9441\t1944.3 examples/second\n",
            "[Step=150]\tLoss=0.1611\tacc=0.9438\t2384.8 examples/second\n",
            "Test Loss=0.3443, Test acc=0.8897\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "[Step=50]\tLoss=0.1556\tacc=0.9451\t1408.1 examples/second\n",
            "[Step=100]\tLoss=0.1604\tacc=0.9441\t2388.4 examples/second\n",
            "[Step=150]\tLoss=0.1598\tacc=0.9438\t1876.5 examples/second\n",
            "Test Loss=0.3452, Test acc=0.8902\n",
            "Saving...\n",
            "\n",
            "Epoch: 18\n",
            "[Step=50]\tLoss=0.1562\tacc=0.9473\t1231.3 examples/second\n",
            "[Step=100]\tLoss=0.1541\tacc=0.9466\t2667.6 examples/second\n",
            "[Step=150]\tLoss=0.1563\tacc=0.9457\t2031.1 examples/second\n",
            "Test Loss=0.3420, Test acc=0.8899\n",
            "\n",
            "Epoch: 19\n",
            "[Step=50]\tLoss=0.1521\tacc=0.9483\t1353.0 examples/second\n",
            "[Step=100]\tLoss=0.1519\tacc=0.9476\t2424.8 examples/second\n",
            "[Step=150]\tLoss=0.1505\tacc=0.9481\t2641.7 examples/second\n",
            "Test Loss=0.3421, Test acc=0.8909\n",
            "Saving...\n"
          ]
        }
      ],
      "source": [
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "best_acc = 0.\n",
        "for epoch in range(20):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "\n",
        "    net.train()\n",
        "    if epoch<10:\n",
        "        for name,layer in net.named_modules():\n",
        "            if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "                # Increase model sparsity\n",
        "                q = (epoch+1)*7\n",
        "                prune_by_percentage(layer, q=q)\n",
        "    if epoch<9:\n",
        "        finetune_after_prune(net, trainloader, criterion, optimizer,prune=False)\n",
        "    else:\n",
        "        finetune_after_prune(net, trainloader, criterion, optimizer)\n",
        "\n",
        "    #Start the testing code.\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    num_val_steps = len(testloader)\n",
        "    val_acc = correct / total\n",
        "    print(\"Test Loss=%.4f, Test acc=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
        "\n",
        "    if epoch>=10:\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            torch.save(net.state_dict(), \"net_after_iterative_prune.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6qrvPAOz8vQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2b31ac-0d13-4d6f-f9fc-e5a8e28beaa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of head_conv.0.conv: 0.6990740740740741\n",
            "Sparsity of body_op.0.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.0.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.1.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.1.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.2.conv1.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.2.conv2.0.conv: 0.7000868055555556\n",
            "Sparsity of body_op.3.conv1.0.conv: 0.6998697916666666\n",
            "Sparsity of body_op.3.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.4.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.4.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.5.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.5.conv2.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.6.conv1.0.conv: 0.6999782986111112\n",
            "Sparsity of body_op.6.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.7.conv1.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.7.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.8.conv1.0.conv: 0.7000054253472222\n",
            "Sparsity of body_op.8.conv2.0.conv: 0.7000054253472222\n",
            "Sparsity of final_fc.linear: 0.7\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3421, Test accuracy=0.8909\n"
          ]
        }
      ],
      "source": [
        "# Check sparsity of the final model, make sure it's 70%\n",
        "net.load_state_dict(torch.load(\"net_after_iterative_prune.pt\"))\n",
        "\n",
        "for name,layer in net.named_modules():\n",
        "    if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "        # Your code here: can copy from previous question\n",
        "         # Convert the weight of \"layer\" to numpy array\n",
        "        np_weight = layer.weight.data.cpu().numpy()\n",
        "        # Count number of zeros\n",
        "        zeros = np.sum(np_weight == 0)\n",
        "        # Count number of parameters\n",
        "        total = np_weight.size\n",
        "        # Print sparsity\n",
        "        print('Sparsity of '+name+': '+str(zeros/total))\n",
        "\n",
        "\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZRhES188vQ7"
      },
      "source": [
        "### Lab2 (e) Global iterative pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5EfrDgBx8vQ7"
      },
      "outputs": [],
      "source": [
        "def global_prune_by_percentage(net, q=70.0):\n",
        "    \"\"\"\n",
        "    Pruning the weight paramters by threshold.\n",
        "    :param q: pruning percentile. 'q' percent of the least\n",
        "    significant weight parameters will be pruned.\n",
        "    \"\"\"\n",
        "    # A list to gather all the weights\n",
        "    flattened_weights = []\n",
        "    # Find global pruning threshold\n",
        "    for name,layer in net.named_modules():\n",
        "        if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "            # Convert weight to numpy\n",
        "            np_weight = layer.weight.data.cpu().numpy()\n",
        "\n",
        "            # Flatten the weight and append to flattened_weights\n",
        "            flattended_weight = np_weight.flatten()\n",
        "            flattened_weights.append(flattended_weight)\n",
        "\n",
        "\n",
        "    # Concate all weights into a np array\n",
        "    flattened_weights = np.concatenate(flattened_weights)\n",
        "    # Find global pruning threshold\n",
        "    thres = np.percentile(np.abs(flattened_weights), q)\n",
        "\n",
        "    # Apply pruning threshold to all layers\n",
        "    for name,layer in net.named_modules():\n",
        "        if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "            # Convert weight to numpy\n",
        "            np_weight = layer.weight.data.cpu().numpy()\n",
        "\n",
        "            # Generate a binary mask same shape as weight to decide which element to prune\n",
        "            mask = (np.abs(np_weight) > thres).astype(np.float32)\n",
        "\n",
        "            # Convert mask to torch tensor and put on GPU\n",
        "            mask = torch.from_numpy(mask).to(device)\n",
        "\n",
        "            # Multiply the weight by mask to perform pruning\n",
        "            layer.weight.data *= mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pj6ZOpl58vQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fad03b1-7c0c-49e2-d797-b280d36d45fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.0481\tacc=0.9852\t1402.2 examples/second\n",
            "[Step=100]\tLoss=0.0477\tacc=0.9855\t2195.9 examples/second\n",
            "[Step=150]\tLoss=0.0469\tacc=0.9861\t2658.5 examples/second\n",
            "Test Loss=0.3242, Test acc=0.9151\n",
            "\n",
            "Epoch: 1\n",
            "[Step=50]\tLoss=0.0503\tacc=0.9842\t1537.9 examples/second\n",
            "[Step=100]\tLoss=0.0475\tacc=0.9848\t1834.4 examples/second\n",
            "[Step=150]\tLoss=0.0474\tacc=0.9851\t2621.5 examples/second\n",
            "Test Loss=0.3267, Test acc=0.9155\n",
            "\n",
            "Epoch: 2\n",
            "[Step=50]\tLoss=0.0480\tacc=0.9845\t1595.6 examples/second\n",
            "[Step=100]\tLoss=0.0476\tacc=0.9854\t1783.7 examples/second\n",
            "[Step=150]\tLoss=0.0486\tacc=0.9847\t2526.8 examples/second\n",
            "Test Loss=0.3281, Test acc=0.9146\n",
            "\n",
            "Epoch: 3\n",
            "[Step=50]\tLoss=0.0512\tacc=0.9847\t1464.0 examples/second\n",
            "[Step=100]\tLoss=0.0516\tacc=0.9837\t2130.5 examples/second\n",
            "[Step=150]\tLoss=0.0523\tacc=0.9834\t2091.4 examples/second\n",
            "Test Loss=0.3310, Test acc=0.9128\n",
            "\n",
            "Epoch: 4\n",
            "[Step=50]\tLoss=0.0522\tacc=0.9823\t1247.4 examples/second\n",
            "[Step=100]\tLoss=0.0524\tacc=0.9827\t2511.4 examples/second\n",
            "[Step=150]\tLoss=0.0534\tacc=0.9823\t1591.2 examples/second\n",
            "Test Loss=0.3283, Test acc=0.9139\n",
            "\n",
            "Epoch: 5\n",
            "[Step=50]\tLoss=0.0608\tacc=0.9806\t1313.3 examples/second\n",
            "[Step=100]\tLoss=0.0611\tacc=0.9799\t2350.1 examples/second\n",
            "[Step=150]\tLoss=0.0609\tacc=0.9800\t1885.6 examples/second\n",
            "Test Loss=0.3251, Test acc=0.9122\n",
            "\n",
            "Epoch: 6\n",
            "[Step=50]\tLoss=0.0702\tacc=0.9762\t1242.0 examples/second\n",
            "[Step=100]\tLoss=0.0699\tacc=0.9759\t2589.2 examples/second\n",
            "[Step=150]\tLoss=0.0710\tacc=0.9752\t1847.9 examples/second\n",
            "Test Loss=0.3264, Test acc=0.9089\n",
            "\n",
            "Epoch: 7\n",
            "[Step=50]\tLoss=0.0954\tacc=0.9666\t1241.8 examples/second\n",
            "[Step=100]\tLoss=0.0925\tacc=0.9677\t2639.1 examples/second\n",
            "[Step=150]\tLoss=0.0898\tacc=0.9688\t2147.6 examples/second\n",
            "Test Loss=0.3298, Test acc=0.9047\n",
            "\n",
            "Epoch: 8\n",
            "[Step=50]\tLoss=0.1177\tacc=0.9598\t1344.6 examples/second\n",
            "[Step=100]\tLoss=0.1189\tacc=0.9589\t2248.1 examples/second\n",
            "[Step=150]\tLoss=0.1165\tacc=0.9596\t2534.0 examples/second\n",
            "Test Loss=0.3264, Test acc=0.9020\n",
            "\n",
            "Epoch: 9\n",
            "[Step=50]\tLoss=0.1816\tacc=0.9361\t1592.3 examples/second\n",
            "[Step=100]\tLoss=0.1747\tacc=0.9395\t1815.7 examples/second\n",
            "[Step=150]\tLoss=0.1712\tacc=0.9411\t2659.5 examples/second\n",
            "Test Loss=0.3452, Test acc=0.8886\n",
            "\n",
            "Epoch: 10\n",
            "[Step=50]\tLoss=0.1625\tacc=0.9445\t1595.8 examples/second\n",
            "[Step=100]\tLoss=0.1590\tacc=0.9455\t1829.2 examples/second\n",
            "[Step=150]\tLoss=0.1567\tacc=0.9464\t2551.7 examples/second\n",
            "Test Loss=0.3354, Test acc=0.8909\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "[Step=50]\tLoss=0.1543\tacc=0.9473\t1472.9 examples/second\n",
            "[Step=100]\tLoss=0.1496\tacc=0.9484\t2077.7 examples/second\n",
            "[Step=150]\tLoss=0.1483\tacc=0.9493\t2182.2 examples/second\n",
            "Test Loss=0.3308, Test acc=0.8936\n",
            "Saving...\n",
            "\n",
            "Epoch: 12\n",
            "[Step=50]\tLoss=0.1474\tacc=0.9481\t1328.4 examples/second\n",
            "[Step=100]\tLoss=0.1436\tacc=0.9500\t2329.1 examples/second\n",
            "[Step=150]\tLoss=0.1462\tacc=0.9484\t1923.9 examples/second\n",
            "Test Loss=0.3266, Test acc=0.8943\n",
            "Saving...\n",
            "\n",
            "Epoch: 13\n",
            "[Step=50]\tLoss=0.1415\tacc=0.9517\t1198.8 examples/second\n",
            "[Step=100]\tLoss=0.1398\tacc=0.9528\t2594.8 examples/second\n",
            "[Step=150]\tLoss=0.1404\tacc=0.9524\t1900.1 examples/second\n",
            "Test Loss=0.3254, Test acc=0.8944\n",
            "Saving...\n",
            "\n",
            "Epoch: 14\n",
            "[Step=50]\tLoss=0.1385\tacc=0.9542\t1180.9 examples/second\n",
            "[Step=100]\tLoss=0.1390\tacc=0.9532\t2584.9 examples/second\n",
            "[Step=150]\tLoss=0.1397\tacc=0.9529\t2249.8 examples/second\n",
            "Test Loss=0.3248, Test acc=0.8951\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=50]\tLoss=0.1384\tacc=0.9544\t1311.6 examples/second\n",
            "[Step=100]\tLoss=0.1357\tacc=0.9550\t2278.5 examples/second\n",
            "[Step=150]\tLoss=0.1364\tacc=0.9543\t2530.2 examples/second\n",
            "Test Loss=0.3220, Test acc=0.8956\n",
            "Saving...\n",
            "\n",
            "Epoch: 16\n",
            "[Step=50]\tLoss=0.1311\tacc=0.9553\t1531.6 examples/second\n",
            "[Step=100]\tLoss=0.1338\tacc=0.9544\t1809.8 examples/second\n",
            "[Step=150]\tLoss=0.1324\tacc=0.9548\t2573.9 examples/second\n",
            "Test Loss=0.3214, Test acc=0.8969\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "[Step=50]\tLoss=0.1246\tacc=0.9569\t1562.0 examples/second\n",
            "[Step=100]\tLoss=0.1298\tacc=0.9554\t1791.7 examples/second\n",
            "[Step=150]\tLoss=0.1304\tacc=0.9552\t2474.4 examples/second\n",
            "Test Loss=0.3194, Test acc=0.8968\n",
            "\n",
            "Epoch: 18\n",
            "[Step=50]\tLoss=0.1305\tacc=0.9563\t1448.2 examples/second\n",
            "[Step=100]\tLoss=0.1305\tacc=0.9563\t2137.6 examples/second\n",
            "[Step=150]\tLoss=0.1289\tacc=0.9570\t2016.6 examples/second\n",
            "Test Loss=0.3176, Test acc=0.8972\n",
            "Saving...\n",
            "\n",
            "Epoch: 19\n",
            "[Step=50]\tLoss=0.1285\tacc=0.9571\t1221.8 examples/second\n",
            "[Step=100]\tLoss=0.1242\tacc=0.9580\t2620.1 examples/second\n",
            "[Step=150]\tLoss=0.1236\tacc=0.9586\t1769.3 examples/second\n",
            "Test Loss=0.3179, Test acc=0.8972\n"
          ]
        }
      ],
      "source": [
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "best_acc = 0.\n",
        "for epoch in range(20):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    q=(epoch+1)*7\n",
        "\n",
        "    net.train()\n",
        "    # Increase model sparsity\n",
        "    if epoch<10:\n",
        "        global_prune_by_percentage(net, q=q)\n",
        "    if epoch<9:\n",
        "        finetune_after_prune(net, trainloader, criterion, optimizer,prune=False)\n",
        "    else:\n",
        "        finetune_after_prune(net, trainloader, criterion, optimizer)\n",
        "\n",
        "    #Start the testing code.\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    num_val_steps = len(testloader)\n",
        "    val_acc = correct / total\n",
        "    print(\"Test Loss=%.4f, Test acc=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
        "\n",
        "    if epoch>=10:\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            torch.save(net.state_dict(), \"net_after_global_iterative_prune.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "40xPIhOp8vQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff550cd-ef3a-44d6-e85a-dc9318a982f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of head_conv.0.conv: 0.24305555555555555\n",
            "Sparsity of body_op.0.conv1.0.conv: 0.5503472222222222\n",
            "Sparsity of body_op.0.conv2.0.conv: 0.5295138888888888\n",
            "Sparsity of body_op.1.conv1.0.conv: 0.5186631944444444\n",
            "Sparsity of body_op.1.conv2.0.conv: 0.5525173611111112\n",
            "Sparsity of body_op.2.conv1.0.conv: 0.5186631944444444\n",
            "Sparsity of body_op.2.conv2.0.conv: 0.5655381944444444\n",
            "Sparsity of body_op.3.conv1.0.conv: 0.5251736111111112\n",
            "Sparsity of body_op.3.conv2.0.conv: 0.5830078125\n",
            "Sparsity of body_op.4.conv1.0.conv: 0.6159939236111112\n",
            "Sparsity of body_op.4.conv2.0.conv: 0.6763237847222222\n",
            "Sparsity of body_op.5.conv1.0.conv: 0.6111111111111112\n",
            "Sparsity of body_op.5.conv2.0.conv: 0.7034505208333334\n",
            "Sparsity of body_op.6.conv1.0.conv: 0.6154513888888888\n",
            "Sparsity of body_op.6.conv2.0.conv: 0.6510959201388888\n",
            "Sparsity of body_op.7.conv1.0.conv: 0.6623263888888888\n",
            "Sparsity of body_op.7.conv2.0.conv: 0.718994140625\n",
            "Sparsity of body_op.8.conv1.0.conv: 0.7478841145833334\n",
            "Sparsity of body_op.8.conv2.0.conv: 0.9371202256944444\n",
            "Sparsity of final_fc.linear: 0.1171875\n",
            "Total sparsity of: 0.6999992546657922\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3176, Test accuracy=0.8972\n"
          ]
        }
      ],
      "source": [
        "net.load_state_dict(torch.load(\"net_after_global_iterative_prune.pt\"))\n",
        "\n",
        "zeros_sum = 0\n",
        "total_sum = 0\n",
        "for name,layer in net.named_modules():\n",
        "    if (isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)) and 'id_mapping' not in name:\n",
        "        # Your code here:\n",
        "        # Convert the weight of \"layer\" to numpy array\n",
        "        np_weight = layer.weight.data.cpu().numpy()\n",
        "        # Count number of zeros\n",
        "        zeros = np.sum(np_weight == 0)\n",
        "        # Count number of parameters\n",
        "        total = np_weight.size\n",
        "        zeros_sum+=zeros\n",
        "        total_sum+=total\n",
        "        print('Sparsity of '+name+': '+str(zeros/total))\n",
        "print('Total sparsity of: '+str(zeros_sum/total_sum))\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdwsVJDu8vQ8"
      },
      "source": [
        "### Lab 3 (b) and (c): Fixed-point quantization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 6 #Change this value to finish (b) and (c)\n",
        "\n",
        "net_6 = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_6 = net_6.to(device)\n",
        "net_6.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5KJI5GcL4X1",
        "outputId": "71d89636-ab32-4e23-c056-467691de3ae3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3364, Test accuracy=0.9145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 5 #Change this value to finish (b) and (c)\n",
        "\n",
        "net_5 = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_5 = net_5.to(device)\n",
        "net_5.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQ6jIC4hYJD",
        "outputId": "c10606d5-c245-4e20-f86b-d62c0d3458ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3390, Test accuracy=0.9112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 4 #Change this value to finish (b) and (c)\n",
        "\n",
        "net_4 = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_4 = net_4.to(device)\n",
        "net_4.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qasekbUUhkow",
        "outputId": "fc605df8-ca76-49c0-c8c5-54fec3a52c7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3861, Test accuracy=0.8972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 3 #Change this value to finish (b) and (c)\n",
        "\n",
        "net_3 = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_3 = net_3.to(device)\n",
        "net_3.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OBDNquChrs9",
        "outputId": "1caa5e71-4f97-42d5-a7f6-ea0598d2433c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.9874, Test accuracy=0.7662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 2 #Change this value to finish (b) and (c)\n",
        "\n",
        "net_2 = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_2 = net_2.to(device)\n",
        "net_2.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYa6jD4Nh1q5",
        "outputId": "6e818b4b-6d36-4227-a970-f89342e15c60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=9.5441, Test accuracy=0.0899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WF3dZXTQ8vQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d44c1c-cfbb-4487-f98c-d907561d7f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.0682\tacc=0.9778\t1131.3 examples/second\n",
            "[Step=100]\tLoss=0.0642\tacc=0.9790\t2329.1 examples/second\n",
            "[Step=150]\tLoss=0.0655\tacc=0.9781\t1698.5 examples/second\n",
            "Test Loss=0.3342, Test acc=0.9090\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=0.0630\tacc=0.9795\t917.7 examples/second\n",
            "[Step=250]\tLoss=0.0626\tacc=0.9800\t2080.9 examples/second\n",
            "[Step=300]\tLoss=0.0643\tacc=0.9790\t2039.2 examples/second\n",
            "[Step=350]\tLoss=0.0627\tacc=0.9793\t1755.5 examples/second\n",
            "Test Loss=0.3360, Test acc=0.9110\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=0.0494\tacc=0.9824\t979.1 examples/second\n",
            "[Step=450]\tLoss=0.0619\tacc=0.9784\t2266.8 examples/second\n",
            "[Step=500]\tLoss=0.0598\tacc=0.9792\t1713.2 examples/second\n",
            "[Step=550]\tLoss=0.0603\tacc=0.9796\t2124.4 examples/second\n",
            "Test Loss=0.3341, Test acc=0.9106\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=0.0518\tacc=0.9840\t981.2 examples/second\n",
            "[Step=650]\tLoss=0.0587\tacc=0.9812\t2272.8 examples/second\n",
            "[Step=700]\tLoss=0.0604\tacc=0.9801\t1652.3 examples/second\n",
            "[Step=750]\tLoss=0.0601\tacc=0.9799\t2180.0 examples/second\n",
            "Test Loss=0.3319, Test acc=0.9115\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=0.0599\tacc=0.9812\t976.9 examples/second\n",
            "[Step=850]\tLoss=0.0588\tacc=0.9798\t1907.7 examples/second\n",
            "[Step=900]\tLoss=0.0573\tacc=0.9804\t1922.6 examples/second\n",
            "[Step=950]\tLoss=0.0585\tacc=0.9798\t2179.1 examples/second\n",
            "Test Loss=0.3280, Test acc=0.9127\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=0.0539\tacc=0.9812\t985.6 examples/second\n",
            "[Step=1050]\tLoss=0.0567\tacc=0.9810\t1642.4 examples/second\n",
            "[Step=1100]\tLoss=0.0591\tacc=0.9800\t2169.8 examples/second\n",
            "[Step=1150]\tLoss=0.0590\tacc=0.9801\t2122.3 examples/second\n",
            "Test Loss=0.3289, Test acc=0.9136\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=0.0554\tacc=0.9826\t1034.9 examples/second\n",
            "[Step=1250]\tLoss=0.0572\tacc=0.9804\t1645.1 examples/second\n",
            "[Step=1300]\tLoss=0.0555\tacc=0.9817\t2182.6 examples/second\n",
            "[Step=1350]\tLoss=0.0568\tacc=0.9814\t2134.5 examples/second\n",
            "Test Loss=0.3314, Test acc=0.9128\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=0.0599\tacc=0.9791\t1038.8 examples/second\n",
            "[Step=1450]\tLoss=0.0578\tacc=0.9797\t1606.4 examples/second\n",
            "[Step=1500]\tLoss=0.0573\tacc=0.9802\t2200.5 examples/second\n",
            "[Step=1550]\tLoss=0.0569\tacc=0.9807\t2247.2 examples/second\n",
            "Test Loss=0.3299, Test acc=0.9123\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=0.0556\tacc=0.9816\t1013.6 examples/second\n",
            "[Step=1650]\tLoss=0.0555\tacc=0.9816\t1670.2 examples/second\n",
            "[Step=1700]\tLoss=0.0560\tacc=0.9817\t2182.9 examples/second\n",
            "[Step=1750]\tLoss=0.0569\tacc=0.9810\t2279.3 examples/second\n",
            "Test Loss=0.3332, Test acc=0.9123\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=0.0574\tacc=0.9825\t1000.1 examples/second\n",
            "[Step=1850]\tLoss=0.0556\tacc=0.9822\t1681.7 examples/second\n",
            "[Step=1900]\tLoss=0.0563\tacc=0.9815\t2204.3 examples/second\n",
            "[Step=1950]\tLoss=0.0562\tacc=0.9817\t2350.9 examples/second\n",
            "Test Loss=0.3293, Test acc=0.9125\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=0.0544\tacc=0.9808\t962.2 examples/second\n",
            "[Step=2050]\tLoss=0.0549\tacc=0.9809\t1738.5 examples/second\n",
            "[Step=2100]\tLoss=0.0549\tacc=0.9815\t2302.3 examples/second\n",
            "[Step=2150]\tLoss=0.0546\tacc=0.9814\t2418.2 examples/second\n",
            "Test Loss=0.3323, Test acc=0.9128\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=0.0526\tacc=0.9832\t927.2 examples/second\n",
            "[Step=2250]\tLoss=0.0548\tacc=0.9825\t1774.1 examples/second\n",
            "[Step=2300]\tLoss=0.0567\tacc=0.9816\t2258.8 examples/second\n",
            "[Step=2350]\tLoss=0.0563\tacc=0.9819\t2482.6 examples/second\n",
            "Test Loss=0.3337, Test acc=0.9127\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=0.0531\tacc=0.9820\t907.2 examples/second\n",
            "[Step=2450]\tLoss=0.0523\tacc=0.9827\t1878.4 examples/second\n",
            "[Step=2500]\tLoss=0.0529\tacc=0.9826\t2312.7 examples/second\n",
            "Test Loss=0.3342, Test acc=0.9111\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=0.0415\tacc=0.9844\t1072.4 examples/second\n",
            "[Step=2600]\tLoss=0.0533\tacc=0.9823\t1651.0 examples/second\n",
            "[Step=2650]\tLoss=0.0533\tacc=0.9828\t1913.8 examples/second\n",
            "[Step=2700]\tLoss=0.0542\tacc=0.9824\t2309.0 examples/second\n",
            "Test Loss=0.3310, Test acc=0.9120\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=0.0585\tacc=0.9811\t1019.2 examples/second\n",
            "[Step=2800]\tLoss=0.0526\tacc=0.9828\t1764.2 examples/second\n",
            "[Step=2850]\tLoss=0.0525\tacc=0.9832\t1941.9 examples/second\n",
            "[Step=2900]\tLoss=0.0525\tacc=0.9833\t2309.0 examples/second\n",
            "Test Loss=0.3343, Test acc=0.9124\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=0.0501\tacc=0.9840\t1041.2 examples/second\n",
            "[Step=3000]\tLoss=0.0530\tacc=0.9829\t1857.6 examples/second\n",
            "[Step=3050]\tLoss=0.0531\tacc=0.9830\t1923.7 examples/second\n",
            "[Step=3100]\tLoss=0.0529\tacc=0.9831\t2302.2 examples/second\n",
            "Test Loss=0.3339, Test acc=0.9118\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=0.0563\tacc=0.9799\t1058.2 examples/second\n",
            "[Step=3200]\tLoss=0.0528\tacc=0.9825\t1719.0 examples/second\n",
            "[Step=3250]\tLoss=0.0526\tacc=0.9827\t2072.9 examples/second\n",
            "[Step=3300]\tLoss=0.0527\tacc=0.9829\t2158.2 examples/second\n",
            "Test Loss=0.3339, Test acc=0.9102\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=0.0546\tacc=0.9813\t1069.2 examples/second\n",
            "[Step=3400]\tLoss=0.0517\tacc=0.9825\t1645.5 examples/second\n",
            "[Step=3450]\tLoss=0.0549\tacc=0.9812\t2190.7 examples/second\n",
            "[Step=3500]\tLoss=0.0545\tacc=0.9816\t2129.8 examples/second\n",
            "Test Loss=0.3320, Test acc=0.9129\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=0.0523\tacc=0.9849\t1053.4 examples/second\n",
            "[Step=3600]\tLoss=0.0507\tacc=0.9838\t1583.2 examples/second\n",
            "[Step=3650]\tLoss=0.0501\tacc=0.9836\t2268.1 examples/second\n",
            "[Step=3700]\tLoss=0.0518\tacc=0.9833\t2363.7 examples/second\n",
            "Test Loss=0.3345, Test acc=0.9120\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=0.0511\tacc=0.9842\t1036.9 examples/second\n",
            "[Step=3800]\tLoss=0.0500\tacc=0.9841\t1590.7 examples/second\n",
            "[Step=3850]\tLoss=0.0526\tacc=0.9827\t2260.7 examples/second\n",
            "[Step=3900]\tLoss=0.0527\tacc=0.9828\t2363.1 examples/second\n",
            "Test Loss=0.3360, Test acc=0.9130\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3289, Test accuracy=0.9136\n"
          ]
        }
      ],
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_4, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_4.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_3, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_3.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQSsEe34uy2J",
        "outputId": "6535a50c-d820-445a-d935-dd223db4bd28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.1657\tacc=0.9393\t1299.6 examples/second\n",
            "[Step=100]\tLoss=0.1573\tacc=0.9437\t1935.2 examples/second\n",
            "[Step=150]\tLoss=0.1484\tacc=0.9474\t2486.3 examples/second\n",
            "Test Loss=0.3991, Test acc=0.8948\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=0.1444\tacc=0.9502\t1011.6 examples/second\n",
            "[Step=250]\tLoss=0.1339\tacc=0.9514\t1857.6 examples/second\n",
            "[Step=300]\tLoss=0.1280\tacc=0.9535\t2084.4 examples/second\n",
            "[Step=350]\tLoss=0.1247\tacc=0.9550\t2416.3 examples/second\n",
            "Test Loss=0.3868, Test acc=0.8977\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=0.1101\tacc=0.9580\t1079.4 examples/second\n",
            "[Step=450]\tLoss=0.1137\tacc=0.9581\t1999.2 examples/second\n",
            "[Step=500]\tLoss=0.1118\tacc=0.9597\t2038.3 examples/second\n",
            "[Step=550]\tLoss=0.1143\tacc=0.9592\t2418.3 examples/second\n",
            "Test Loss=0.3725, Test acc=0.8995\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=0.1050\tacc=0.9613\t1059.2 examples/second\n",
            "[Step=650]\tLoss=0.1086\tacc=0.9621\t1937.0 examples/second\n",
            "[Step=700]\tLoss=0.1059\tacc=0.9625\t2132.0 examples/second\n",
            "[Step=750]\tLoss=0.1079\tacc=0.9613\t2393.9 examples/second\n",
            "Test Loss=0.3701, Test acc=0.9024\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=0.0902\tacc=0.9670\t1080.3 examples/second\n",
            "[Step=850]\tLoss=0.1023\tacc=0.9635\t1889.9 examples/second\n",
            "[Step=900]\tLoss=0.1029\tacc=0.9636\t2128.5 examples/second\n",
            "[Step=950]\tLoss=0.1035\tacc=0.9634\t2403.1 examples/second\n",
            "Test Loss=0.3728, Test acc=0.8996\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=0.0997\tacc=0.9643\t1056.0 examples/second\n",
            "[Step=1050]\tLoss=0.1018\tacc=0.9629\t1868.8 examples/second\n",
            "[Step=1100]\tLoss=0.1005\tacc=0.9635\t2096.1 examples/second\n",
            "[Step=1150]\tLoss=0.1022\tacc=0.9628\t2502.5 examples/second\n",
            "Test Loss=0.3650, Test acc=0.9042\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=0.1025\tacc=0.9618\t1019.6 examples/second\n",
            "[Step=1250]\tLoss=0.1017\tacc=0.9633\t1696.9 examples/second\n",
            "[Step=1300]\tLoss=0.1005\tacc=0.9633\t2317.2 examples/second\n",
            "[Step=1350]\tLoss=0.1014\tacc=0.9628\t2581.4 examples/second\n",
            "Test Loss=0.3700, Test acc=0.9039\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=0.0997\tacc=0.9640\t1050.8 examples/second\n",
            "[Step=1450]\tLoss=0.0971\tacc=0.9648\t1716.2 examples/second\n",
            "[Step=1500]\tLoss=0.0968\tacc=0.9652\t2392.8 examples/second\n",
            "[Step=1550]\tLoss=0.0981\tacc=0.9648\t2613.5 examples/second\n",
            "Test Loss=0.3682, Test acc=0.9011\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=0.1007\tacc=0.9628\t1002.3 examples/second\n",
            "[Step=1650]\tLoss=0.0963\tacc=0.9640\t1693.2 examples/second\n",
            "[Step=1700]\tLoss=0.0952\tacc=0.9651\t2374.4 examples/second\n",
            "[Step=1750]\tLoss=0.0964\tacc=0.9646\t2741.3 examples/second\n",
            "Test Loss=0.3639, Test acc=0.9039\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=0.0925\tacc=0.9654\t1001.5 examples/second\n",
            "[Step=1850]\tLoss=0.0927\tacc=0.9653\t1705.7 examples/second\n",
            "[Step=1900]\tLoss=0.0957\tacc=0.9645\t2392.5 examples/second\n",
            "[Step=1950]\tLoss=0.0945\tacc=0.9651\t2632.4 examples/second\n",
            "Test Loss=0.3701, Test acc=0.9032\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=0.0905\tacc=0.9677\t970.8 examples/second\n",
            "[Step=2050]\tLoss=0.0935\tacc=0.9670\t1770.3 examples/second\n",
            "[Step=2100]\tLoss=0.0929\tacc=0.9669\t2373.3 examples/second\n",
            "[Step=2150]\tLoss=0.0918\tacc=0.9677\t2758.0 examples/second\n",
            "Test Loss=0.3671, Test acc=0.9036\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=0.0868\tacc=0.9685\t948.7 examples/second\n",
            "[Step=2250]\tLoss=0.0906\tacc=0.9680\t1838.6 examples/second\n",
            "[Step=2300]\tLoss=0.0927\tacc=0.9671\t2385.9 examples/second\n",
            "[Step=2350]\tLoss=0.0921\tacc=0.9673\t2909.1 examples/second\n",
            "Test Loss=0.3680, Test acc=0.9027\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=0.0895\tacc=0.9678\t894.5 examples/second\n",
            "[Step=2450]\tLoss=0.0923\tacc=0.9676\t1936.8 examples/second\n",
            "[Step=2500]\tLoss=0.0919\tacc=0.9675\t2345.6 examples/second\n",
            "Test Loss=0.3569, Test acc=0.9042\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=0.0971\tacc=0.9668\t1149.5 examples/second\n",
            "[Step=2600]\tLoss=0.0947\tacc=0.9661\t1663.4 examples/second\n",
            "[Step=2650]\tLoss=0.0935\tacc=0.9671\t2007.1 examples/second\n",
            "[Step=2700]\tLoss=0.0938\tacc=0.9666\t2358.7 examples/second\n",
            "Test Loss=0.3541, Test acc=0.9041\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=0.0822\tacc=0.9701\t1069.6 examples/second\n",
            "[Step=2800]\tLoss=0.0884\tacc=0.9681\t1754.6 examples/second\n",
            "[Step=2850]\tLoss=0.0886\tacc=0.9686\t2044.8 examples/second\n",
            "[Step=2900]\tLoss=0.0901\tacc=0.9679\t2332.3 examples/second\n",
            "Test Loss=0.3697, Test acc=0.9038\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=0.0821\tacc=0.9695\t1053.2 examples/second\n",
            "[Step=3000]\tLoss=0.0908\tacc=0.9672\t1740.0 examples/second\n",
            "[Step=3050]\tLoss=0.0915\tacc=0.9666\t2109.4 examples/second\n",
            "[Step=3100]\tLoss=0.0899\tacc=0.9672\t2332.2 examples/second\n",
            "Test Loss=0.3589, Test acc=0.9049\n",
            "Saving...\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=0.0947\tacc=0.9685\t1056.5 examples/second\n",
            "[Step=3200]\tLoss=0.0886\tacc=0.9689\t1746.1 examples/second\n",
            "[Step=3250]\tLoss=0.0869\tacc=0.9697\t2098.8 examples/second\n",
            "[Step=3300]\tLoss=0.0877\tacc=0.9691\t2344.4 examples/second\n",
            "Test Loss=0.3603, Test acc=0.9023\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=0.0931\tacc=0.9657\t1065.6 examples/second\n",
            "[Step=3400]\tLoss=0.0854\tacc=0.9696\t1758.9 examples/second\n",
            "[Step=3450]\tLoss=0.0865\tacc=0.9688\t2138.1 examples/second\n",
            "[Step=3500]\tLoss=0.0876\tacc=0.9684\t2426.3 examples/second\n",
            "Test Loss=0.3652, Test acc=0.9046\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=0.0947\tacc=0.9693\t1001.4 examples/second\n",
            "[Step=3600]\tLoss=0.0899\tacc=0.9692\t1712.3 examples/second\n",
            "[Step=3650]\tLoss=0.0877\tacc=0.9697\t2163.3 examples/second\n",
            "[Step=3700]\tLoss=0.0893\tacc=0.9689\t2519.0 examples/second\n",
            "Test Loss=0.3592, Test acc=0.9042\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=0.0786\tacc=0.9740\t1013.0 examples/second\n",
            "[Step=3800]\tLoss=0.0824\tacc=0.9720\t1658.5 examples/second\n",
            "[Step=3850]\tLoss=0.0832\tacc=0.9714\t2293.0 examples/second\n",
            "[Step=3900]\tLoss=0.0837\tacc=0.9710\t2570.5 examples/second\n",
            "Test Loss=0.3517, Test acc=0.9034\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3589, Test accuracy=0.9049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_2, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_2.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk7Ezghdyz7h",
        "outputId": "c8d337e3-7f98-4abb-cee2-6f908c9c84ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=1.3754\tacc=0.6118\t1139.5 examples/second\n",
            "[Step=100]\tLoss=1.0772\tacc=0.6816\t2348.6 examples/second\n",
            "[Step=150]\tLoss=0.9408\tacc=0.7145\t1707.2 examples/second\n",
            "Test Loss=0.7622, Test acc=0.7730\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=0.5926\tacc=0.7998\t1024.2 examples/second\n",
            "[Step=250]\tLoss=0.5690\tacc=0.8078\t1838.6 examples/second\n",
            "[Step=300]\tLoss=0.5601\tacc=0.8114\t2264.3 examples/second\n",
            "[Step=350]\tLoss=0.5425\tacc=0.8157\t1741.9 examples/second\n",
            "Test Loss=0.6558, Test acc=0.7991\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=0.4834\tacc=0.8306\t932.0 examples/second\n",
            "[Step=450]\tLoss=0.4752\tacc=0.8339\t2079.8 examples/second\n",
            "[Step=500]\tLoss=0.4716\tacc=0.8365\t2361.6 examples/second\n",
            "[Step=550]\tLoss=0.4629\tacc=0.8402\t1669.0 examples/second\n",
            "Test Loss=0.5729, Test acc=0.8211\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=0.4331\tacc=0.8512\t936.9 examples/second\n",
            "[Step=650]\tLoss=0.4241\tacc=0.8532\t2199.1 examples/second\n",
            "[Step=700]\tLoss=0.4298\tacc=0.8522\t2265.1 examples/second\n",
            "[Step=750]\tLoss=0.4245\tacc=0.8528\t1722.3 examples/second\n",
            "Test Loss=0.5782, Test acc=0.8248\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=0.4088\tacc=0.8557\t943.6 examples/second\n",
            "[Step=850]\tLoss=0.4045\tacc=0.8590\t2167.7 examples/second\n",
            "[Step=900]\tLoss=0.4028\tacc=0.8602\t2175.2 examples/second\n",
            "[Step=950]\tLoss=0.3985\tacc=0.8619\t1771.7 examples/second\n",
            "Test Loss=0.5428, Test acc=0.8354\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=0.4031\tacc=0.8562\t902.1 examples/second\n",
            "[Step=1050]\tLoss=0.3927\tacc=0.8643\t2216.1 examples/second\n",
            "[Step=1100]\tLoss=0.3866\tacc=0.8667\t2166.8 examples/second\n",
            "[Step=1150]\tLoss=0.3804\tacc=0.8682\t1851.7 examples/second\n",
            "Test Loss=0.5261, Test acc=0.8375\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=0.3657\tacc=0.8695\t915.4 examples/second\n",
            "[Step=1250]\tLoss=0.3762\tacc=0.8673\t2305.7 examples/second\n",
            "[Step=1300]\tLoss=0.3721\tacc=0.8691\t2160.5 examples/second\n",
            "[Step=1350]\tLoss=0.3662\tacc=0.8717\t1880.4 examples/second\n",
            "Test Loss=0.6214, Test acc=0.8189\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=0.3589\tacc=0.8771\t892.0 examples/second\n",
            "[Step=1450]\tLoss=0.3539\tacc=0.8791\t2235.5 examples/second\n",
            "[Step=1500]\tLoss=0.3486\tacc=0.8790\t1997.4 examples/second\n",
            "[Step=1550]\tLoss=0.3490\tacc=0.8789\t2149.9 examples/second\n",
            "Test Loss=0.5454, Test acc=0.8283\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=0.3492\tacc=0.8760\t903.5 examples/second\n",
            "[Step=1650]\tLoss=0.3417\tacc=0.8794\t2349.5 examples/second\n",
            "[Step=1700]\tLoss=0.3426\tacc=0.8796\t1908.3 examples/second\n",
            "[Step=1750]\tLoss=0.3422\tacc=0.8795\t2169.0 examples/second\n",
            "Test Loss=0.6158, Test acc=0.8198\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=0.3309\tacc=0.8840\t903.0 examples/second\n",
            "[Step=1850]\tLoss=0.3280\tacc=0.8833\t2332.5 examples/second\n",
            "[Step=1900]\tLoss=0.3294\tacc=0.8835\t1879.9 examples/second\n",
            "[Step=1950]\tLoss=0.3319\tacc=0.8829\t2370.7 examples/second\n",
            "Test Loss=0.5714, Test acc=0.8262\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=0.3315\tacc=0.8831\t803.4 examples/second\n",
            "[Step=2050]\tLoss=0.3265\tacc=0.8856\t2291.2 examples/second\n",
            "[Step=2100]\tLoss=0.3259\tacc=0.8856\t1676.2 examples/second\n",
            "[Step=2150]\tLoss=0.3235\tacc=0.8859\t2811.5 examples/second\n",
            "Test Loss=0.5049, Test acc=0.8469\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=0.3095\tacc=0.8938\t895.9 examples/second\n",
            "[Step=2250]\tLoss=0.3097\tacc=0.8921\t2120.2 examples/second\n",
            "[Step=2300]\tLoss=0.3094\tacc=0.8924\t1812.6 examples/second\n",
            "[Step=2350]\tLoss=0.3127\tacc=0.8905\t3015.0 examples/second\n",
            "Test Loss=0.5119, Test acc=0.8437\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=0.3257\tacc=0.8862\t907.8 examples/second\n",
            "[Step=2450]\tLoss=0.3177\tacc=0.8879\t1915.4 examples/second\n",
            "[Step=2500]\tLoss=0.3172\tacc=0.8895\t1999.9 examples/second\n",
            "Test Loss=0.5461, Test acc=0.8380\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=0.3506\tacc=0.8672\t1067.6 examples/second\n",
            "[Step=2600]\tLoss=0.3137\tacc=0.8919\t2001.4 examples/second\n",
            "[Step=2650]\tLoss=0.3032\tacc=0.8928\t1737.6 examples/second\n",
            "[Step=2700]\tLoss=0.3029\tacc=0.8930\t2250.8 examples/second\n",
            "Test Loss=0.4776, Test acc=0.8530\n",
            "Saving...\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=0.2833\tacc=0.9056\t968.1 examples/second\n",
            "[Step=2800]\tLoss=0.2978\tacc=0.8954\t2117.9 examples/second\n",
            "[Step=2850]\tLoss=0.2941\tacc=0.8962\t1623.6 examples/second\n",
            "[Step=2900]\tLoss=0.2936\tacc=0.8959\t2203.9 examples/second\n",
            "Test Loss=0.4548, Test acc=0.8586\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=0.2929\tacc=0.8969\t987.0 examples/second\n",
            "[Step=3000]\tLoss=0.2943\tacc=0.8964\t1908.3 examples/second\n",
            "[Step=3050]\tLoss=0.2924\tacc=0.8978\t1953.7 examples/second\n",
            "[Step=3100]\tLoss=0.2941\tacc=0.8970\t2232.9 examples/second\n",
            "Test Loss=0.4677, Test acc=0.8525\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=0.2816\tacc=0.9023\t1058.0 examples/second\n",
            "[Step=3200]\tLoss=0.2823\tacc=0.9002\t1789.9 examples/second\n",
            "[Step=3250]\tLoss=0.2810\tacc=0.9002\t2165.4 examples/second\n",
            "[Step=3300]\tLoss=0.2827\tacc=0.8993\t2099.9 examples/second\n",
            "Test Loss=0.4719, Test acc=0.8587\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=0.2961\tacc=0.8989\t1044.5 examples/second\n",
            "[Step=3400]\tLoss=0.2856\tacc=0.8964\t1680.4 examples/second\n",
            "[Step=3450]\tLoss=0.2845\tacc=0.8979\t2304.9 examples/second\n",
            "[Step=3500]\tLoss=0.2836\tacc=0.8989\t2088.7 examples/second\n",
            "Test Loss=0.5002, Test acc=0.8472\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=0.2846\tacc=0.8990\t1034.9 examples/second\n",
            "[Step=3600]\tLoss=0.2798\tacc=0.9001\t1675.3 examples/second\n",
            "[Step=3650]\tLoss=0.2799\tacc=0.9001\t2361.3 examples/second\n",
            "[Step=3700]\tLoss=0.2776\tacc=0.9016\t2140.1 examples/second\n",
            "Test Loss=0.4878, Test acc=0.8537\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=0.2840\tacc=0.9016\t1049.3 examples/second\n",
            "[Step=3800]\tLoss=0.2828\tacc=0.9023\t1695.2 examples/second\n",
            "[Step=3850]\tLoss=0.2789\tacc=0.9028\t2377.8 examples/second\n",
            "[Step=3900]\tLoss=0.2775\tacc=0.9027\t2338.1 examples/second\n",
            "Test Loss=0.5776, Test acc=0.8330\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.4719, Test accuracy=0.8587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OnTwEzi8vQ9"
      },
      "source": [
        "### Lab3 (d) Quantize pruned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gu97nMB18vQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae024fc-bfe2-4f13-9b80-b70b10104ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.4115, Test accuracy=0.8722\n"
          ]
        }
      ],
      "source": [
        "# Define quantized model and load weight\n",
        "Nbits = 4 #Change this value to finish (d)\n",
        "\n",
        "net_4B = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_4B= net_4B.to(device)\n",
        "net_4B.load_state_dict(torch.load(\"net_after_global_iterative_prune.pt\"))\n",
        "test(net_4B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ueQsQTqq8vQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095fbfeb-00d8-4c2a-aba4-f3b6aad929ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=0.7270\tacc=0.7520\t1132.4 examples/second\n",
            "[Step=100]\tLoss=0.5061\tacc=0.8271\t2347.7 examples/second\n",
            "[Step=150]\tLoss=0.4209\tacc=0.8557\t1685.8 examples/second\n",
            "Test Loss=0.3579, Test acc=0.8808\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=0.2137\tacc=0.9268\t954.7 examples/second\n",
            "[Step=250]\tLoss=0.2148\tacc=0.9256\t1991.2 examples/second\n",
            "[Step=300]\tLoss=0.2090\tacc=0.9282\t2109.4 examples/second\n",
            "[Step=350]\tLoss=0.2042\tacc=0.9298\t1783.8 examples/second\n",
            "Test Loss=0.3414, Test acc=0.8889\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=0.2014\tacc=0.9243\t953.8 examples/second\n",
            "[Step=450]\tLoss=0.1851\tacc=0.9351\t2376.3 examples/second\n",
            "[Step=500]\tLoss=0.1850\tacc=0.9360\t1996.7 examples/second\n",
            "[Step=550]\tLoss=0.1838\tacc=0.9364\t1940.3 examples/second\n",
            "Test Loss=0.3288, Test acc=0.8940\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=0.1573\tacc=0.9463\t976.6 examples/second\n",
            "[Step=650]\tLoss=0.1695\tacc=0.9412\t2341.7 examples/second\n",
            "[Step=700]\tLoss=0.1720\tacc=0.9410\t1739.8 examples/second\n",
            "[Step=750]\tLoss=0.1697\tacc=0.9413\t2183.0 examples/second\n",
            "Test Loss=0.3196, Test acc=0.8971\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=0.1494\tacc=0.9500\t992.3 examples/second\n",
            "[Step=850]\tLoss=0.1553\tacc=0.9480\t2319.3 examples/second\n",
            "[Step=900]\tLoss=0.1553\tacc=0.9471\t1687.1 examples/second\n",
            "[Step=950]\tLoss=0.1547\tacc=0.9472\t2434.6 examples/second\n",
            "Test Loss=0.3333, Test acc=0.8982\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=0.1435\tacc=0.9492\t989.3 examples/second\n",
            "[Step=1050]\tLoss=0.1431\tacc=0.9504\t2235.5 examples/second\n",
            "[Step=1100]\tLoss=0.1460\tacc=0.9491\t1750.9 examples/second\n",
            "[Step=1150]\tLoss=0.1441\tacc=0.9500\t2465.6 examples/second\n",
            "Test Loss=0.3319, Test acc=0.8981\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=0.1448\tacc=0.9463\t965.9 examples/second\n",
            "[Step=1250]\tLoss=0.1437\tacc=0.9495\t1972.3 examples/second\n",
            "[Step=1300]\tLoss=0.1413\tacc=0.9500\t1964.7 examples/second\n",
            "[Step=1350]\tLoss=0.1402\tacc=0.9501\t2557.7 examples/second\n",
            "Test Loss=0.3341, Test acc=0.8997\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=0.1428\tacc=0.9506\t952.8 examples/second\n",
            "[Step=1450]\tLoss=0.1349\tacc=0.9526\t1746.0 examples/second\n",
            "[Step=1500]\tLoss=0.1350\tacc=0.9528\t2283.1 examples/second\n",
            "[Step=1550]\tLoss=0.1341\tacc=0.9534\t2616.3 examples/second\n",
            "Test Loss=0.3474, Test acc=0.9005\n",
            "Saving...\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=0.1354\tacc=0.9524\t964.0 examples/second\n",
            "[Step=1650]\tLoss=0.1277\tacc=0.9552\t1691.4 examples/second\n",
            "[Step=1700]\tLoss=0.1296\tacc=0.9550\t2329.0 examples/second\n",
            "[Step=1750]\tLoss=0.1267\tacc=0.9559\t2535.2 examples/second\n",
            "Test Loss=0.3417, Test acc=0.9006\n",
            "Saving...\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=0.1230\tacc=0.9562\t964.4 examples/second\n",
            "[Step=1850]\tLoss=0.1228\tacc=0.9563\t1680.4 examples/second\n",
            "[Step=1900]\tLoss=0.1233\tacc=0.9567\t2328.8 examples/second\n",
            "[Step=1950]\tLoss=0.1237\tacc=0.9567\t2771.9 examples/second\n",
            "Test Loss=0.3628, Test acc=0.9002\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=0.1163\tacc=0.9575\t995.5 examples/second\n",
            "[Step=2050]\tLoss=0.1210\tacc=0.9560\t1690.7 examples/second\n",
            "[Step=2100]\tLoss=0.1210\tacc=0.9562\t2379.9 examples/second\n",
            "[Step=2150]\tLoss=0.1216\tacc=0.9563\t2860.9 examples/second\n",
            "Test Loss=0.3402, Test acc=0.9025\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=0.1136\tacc=0.9579\t958.0 examples/second\n",
            "[Step=2250]\tLoss=0.1139\tacc=0.9590\t1800.7 examples/second\n",
            "[Step=2300]\tLoss=0.1174\tacc=0.9579\t2343.1 examples/second\n",
            "[Step=2350]\tLoss=0.1186\tacc=0.9576\t2914.8 examples/second\n",
            "Test Loss=0.3568, Test acc=0.8999\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=0.1166\tacc=0.9589\t917.9 examples/second\n",
            "[Step=2450]\tLoss=0.1167\tacc=0.9590\t1812.0 examples/second\n",
            "[Step=2500]\tLoss=0.1174\tacc=0.9594\t2314.8 examples/second\n",
            "Test Loss=0.3369, Test acc=0.9051\n",
            "Saving...\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=0.0993\tacc=0.9707\t1086.3 examples/second\n",
            "[Step=2600]\tLoss=0.1085\tacc=0.9624\t1689.6 examples/second\n",
            "[Step=2650]\tLoss=0.1113\tacc=0.9604\t2017.1 examples/second\n",
            "[Step=2700]\tLoss=0.1090\tacc=0.9611\t2323.7 examples/second\n",
            "Test Loss=0.3687, Test acc=0.9027\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=0.1017\tacc=0.9622\t1003.3 examples/second\n",
            "[Step=2800]\tLoss=0.1076\tacc=0.9632\t1780.7 examples/second\n",
            "[Step=2850]\tLoss=0.1057\tacc=0.9631\t2117.8 examples/second\n",
            "[Step=2900]\tLoss=0.1073\tacc=0.9618\t2312.4 examples/second\n",
            "Test Loss=0.3490, Test acc=0.9022\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=0.1062\tacc=0.9652\t1007.0 examples/second\n",
            "[Step=3000]\tLoss=0.1075\tacc=0.9630\t1822.5 examples/second\n",
            "[Step=3050]\tLoss=0.1056\tacc=0.9636\t2177.8 examples/second\n",
            "[Step=3100]\tLoss=0.1066\tacc=0.9627\t2336.1 examples/second\n",
            "Test Loss=0.3519, Test acc=0.9016\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=0.1042\tacc=0.9621\t1034.3 examples/second\n",
            "[Step=3200]\tLoss=0.1035\tacc=0.9636\t1763.7 examples/second\n",
            "[Step=3250]\tLoss=0.1054\tacc=0.9625\t2241.7 examples/second\n",
            "[Step=3300]\tLoss=0.1068\tacc=0.9613\t2241.4 examples/second\n",
            "Test Loss=0.3658, Test acc=0.9032\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=0.0941\tacc=0.9670\t1064.4 examples/second\n",
            "[Step=3400]\tLoss=0.1021\tacc=0.9630\t1716.8 examples/second\n",
            "[Step=3450]\tLoss=0.1061\tacc=0.9622\t2345.9 examples/second\n",
            "[Step=3500]\tLoss=0.1062\tacc=0.9617\t2250.7 examples/second\n",
            "Test Loss=0.3308, Test acc=0.9032\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=0.0994\tacc=0.9640\t1050.5 examples/second\n",
            "[Step=3600]\tLoss=0.1019\tacc=0.9633\t1692.1 examples/second\n",
            "[Step=3650]\tLoss=0.0991\tacc=0.9641\t2351.3 examples/second\n",
            "[Step=3700]\tLoss=0.0989\tacc=0.9645\t2408.9 examples/second\n",
            "Test Loss=0.3476, Test acc=0.9021\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=0.1011\tacc=0.9639\t1040.0 examples/second\n",
            "[Step=3800]\tLoss=0.0974\tacc=0.9650\t1701.8 examples/second\n",
            "[Step=3850]\tLoss=0.1000\tacc=0.9644\t2268.2 examples/second\n",
            "[Step=3900]\tLoss=0.0984\tacc=0.9646\t2399.9 examples/second\n",
            "Test Loss=0.3469, Test acc=0.9031\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3369, Test accuracy=0.9051\n"
          ]
        }
      ],
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_4B, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_4B.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_4B)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define quantized model and load weight\n",
        "Nbits = 3 #Change this value to finish (d)\n",
        "\n",
        "net_3B = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_3B= net_3B.to(device)\n",
        "net_3B.load_state_dict(torch.load(\"net_after_global_iterative_prune.pt\"))\n",
        "test(net_3B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhxnZvqhC-3C",
        "outputId": "8b3005e1-b4a4-451b-ea64-c834da7ee640"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=1.1141, Test accuracy=0.6331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_3B, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_3B.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_3B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLM6RZriDNu4",
        "outputId": "ba3d03ad-562f-45a4-a55f-10c39c59de62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=1.4114\tacc=0.5343\t1191.0 examples/second\n",
            "[Step=100]\tLoss=1.1732\tacc=0.6066\t2322.3 examples/second\n",
            "[Step=150]\tLoss=1.0196\tacc=0.6564\t2337.4 examples/second\n",
            "Test Loss=0.6304, Test acc=0.7863\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=0.5586\tacc=0.8027\t1084.2 examples/second\n",
            "[Step=250]\tLoss=0.5164\tacc=0.8226\t1673.1 examples/second\n",
            "[Step=300]\tLoss=0.4947\tacc=0.8310\t2268.7 examples/second\n",
            "[Step=350]\tLoss=0.4795\tacc=0.8362\t2382.3 examples/second\n",
            "Test Loss=0.5143, Test acc=0.8232\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=0.4100\tacc=0.8652\t974.8 examples/second\n",
            "[Step=450]\tLoss=0.4143\tacc=0.8584\t1755.8 examples/second\n",
            "[Step=500]\tLoss=0.4068\tacc=0.8591\t2226.9 examples/second\n",
            "[Step=550]\tLoss=0.3970\tacc=0.8621\t2243.3 examples/second\n",
            "Test Loss=0.4785, Test acc=0.8419\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=0.3470\tacc=0.8773\t1067.1 examples/second\n",
            "[Step=650]\tLoss=0.3470\tacc=0.8793\t1814.1 examples/second\n",
            "[Step=700]\tLoss=0.3511\tacc=0.8783\t2190.2 examples/second\n",
            "[Step=750]\tLoss=0.3444\tacc=0.8802\t2312.3 examples/second\n",
            "Test Loss=0.4630, Test acc=0.8489\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=0.3120\tacc=0.8962\t1067.0 examples/second\n",
            "[Step=850]\tLoss=0.3136\tacc=0.8931\t1738.3 examples/second\n",
            "[Step=900]\tLoss=0.3136\tacc=0.8930\t2284.6 examples/second\n",
            "[Step=950]\tLoss=0.3133\tacc=0.8911\t2303.1 examples/second\n",
            "Test Loss=0.4504, Test acc=0.8561\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=0.3043\tacc=0.8951\t1070.1 examples/second\n",
            "[Step=1050]\tLoss=0.2924\tacc=0.8976\t1732.1 examples/second\n",
            "[Step=1100]\tLoss=0.2934\tacc=0.8977\t2370.7 examples/second\n",
            "[Step=1150]\tLoss=0.2931\tacc=0.8979\t2476.0 examples/second\n",
            "Test Loss=0.4266, Test acc=0.8618\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=0.2709\tacc=0.9059\t1047.4 examples/second\n",
            "[Step=1250]\tLoss=0.2794\tacc=0.9036\t1712.0 examples/second\n",
            "[Step=1300]\tLoss=0.2784\tacc=0.9032\t2410.1 examples/second\n",
            "[Step=1350]\tLoss=0.2778\tacc=0.9038\t2500.0 examples/second\n",
            "Test Loss=0.4137, Test acc=0.8660\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=0.2561\tacc=0.9134\t1029.1 examples/second\n",
            "[Step=1450]\tLoss=0.2654\tacc=0.9075\t1696.5 examples/second\n",
            "[Step=1500]\tLoss=0.2634\tacc=0.9076\t2263.6 examples/second\n",
            "[Step=1550]\tLoss=0.2604\tacc=0.9093\t2473.6 examples/second\n",
            "Test Loss=0.4093, Test acc=0.8696\n",
            "Saving...\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=0.2473\tacc=0.9166\t1032.2 examples/second\n",
            "[Step=1650]\tLoss=0.2513\tacc=0.9148\t1734.6 examples/second\n",
            "[Step=1700]\tLoss=0.2508\tacc=0.9143\t2405.6 examples/second\n",
            "[Step=1750]\tLoss=0.2528\tacc=0.9134\t2653.7 examples/second\n",
            "Test Loss=0.4002, Test acc=0.8716\n",
            "Saving...\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=0.2493\tacc=0.9160\t987.2 examples/second\n",
            "[Step=1850]\tLoss=0.2516\tacc=0.9131\t1726.2 examples/second\n",
            "[Step=1900]\tLoss=0.2493\tacc=0.9130\t2357.2 examples/second\n",
            "[Step=1950]\tLoss=0.2465\tacc=0.9142\t2584.2 examples/second\n",
            "Test Loss=0.4079, Test acc=0.8716\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=0.2372\tacc=0.9185\t973.6 examples/second\n",
            "[Step=2050]\tLoss=0.2337\tacc=0.9178\t1826.3 examples/second\n",
            "[Step=2100]\tLoss=0.2343\tacc=0.9182\t2398.1 examples/second\n",
            "[Step=2150]\tLoss=0.2324\tacc=0.9183\t2785.0 examples/second\n",
            "Test Loss=0.3941, Test acc=0.8760\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=0.2257\tacc=0.9197\t907.3 examples/second\n",
            "[Step=2250]\tLoss=0.2242\tacc=0.9206\t1880.9 examples/second\n",
            "[Step=2300]\tLoss=0.2276\tacc=0.9195\t2395.7 examples/second\n",
            "[Step=2350]\tLoss=0.2246\tacc=0.9206\t2766.5 examples/second\n",
            "Test Loss=0.3893, Test acc=0.8756\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=0.2302\tacc=0.9182\t896.2 examples/second\n",
            "[Step=2450]\tLoss=0.2250\tacc=0.9199\t1895.7 examples/second\n",
            "[Step=2500]\tLoss=0.2229\tacc=0.9206\t2352.7 examples/second\n",
            "Test Loss=0.3872, Test acc=0.8783\n",
            "Saving...\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=0.2643\tacc=0.9141\t1120.1 examples/second\n",
            "[Step=2600]\tLoss=0.2132\tacc=0.9227\t1693.0 examples/second\n",
            "[Step=2650]\tLoss=0.2154\tacc=0.9229\t2033.6 examples/second\n",
            "[Step=2700]\tLoss=0.2172\tacc=0.9230\t2409.3 examples/second\n",
            "Test Loss=0.3782, Test acc=0.8797\n",
            "Saving...\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=0.2156\tacc=0.9232\t1050.1 examples/second\n",
            "[Step=2800]\tLoss=0.2127\tacc=0.9256\t1822.7 examples/second\n",
            "[Step=2850]\tLoss=0.2110\tacc=0.9250\t2125.4 examples/second\n",
            "[Step=2900]\tLoss=0.2097\tacc=0.9259\t2371.2 examples/second\n",
            "Test Loss=0.3759, Test acc=0.8808\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=0.2107\tacc=0.9277\t1037.5 examples/second\n",
            "[Step=3000]\tLoss=0.2112\tacc=0.9257\t1812.0 examples/second\n",
            "[Step=3050]\tLoss=0.2070\tacc=0.9266\t2263.7 examples/second\n",
            "[Step=3100]\tLoss=0.2070\tacc=0.9272\t2400.3 examples/second\n",
            "Test Loss=0.3811, Test acc=0.8795\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=0.1911\tacc=0.9280\t1042.5 examples/second\n",
            "[Step=3200]\tLoss=0.1977\tacc=0.9295\t1758.9 examples/second\n",
            "[Step=3250]\tLoss=0.2033\tacc=0.9277\t2315.5 examples/second\n",
            "[Step=3300]\tLoss=0.2032\tacc=0.9281\t2319.6 examples/second\n",
            "Test Loss=0.3859, Test acc=0.8780\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=0.2061\tacc=0.9269\t1064.0 examples/second\n",
            "[Step=3400]\tLoss=0.2018\tacc=0.9266\t1653.6 examples/second\n",
            "[Step=3450]\tLoss=0.2001\tacc=0.9282\t2374.6 examples/second\n",
            "[Step=3500]\tLoss=0.1980\tacc=0.9290\t2299.7 examples/second\n",
            "Test Loss=0.3636, Test acc=0.8846\n",
            "Saving...\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=0.1898\tacc=0.9318\t1074.3 examples/second\n",
            "[Step=3600]\tLoss=0.1940\tacc=0.9306\t1654.4 examples/second\n",
            "[Step=3650]\tLoss=0.1938\tacc=0.9315\t2385.2 examples/second\n",
            "[Step=3700]\tLoss=0.1948\tacc=0.9313\t2416.1 examples/second\n",
            "Test Loss=0.3791, Test acc=0.8791\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=0.1855\tacc=0.9331\t1062.8 examples/second\n",
            "[Step=3800]\tLoss=0.1882\tacc=0.9337\t1638.1 examples/second\n",
            "[Step=3850]\tLoss=0.1902\tacc=0.9330\t2423.2 examples/second\n",
            "[Step=3900]\tLoss=0.1908\tacc=0.9330\t2560.5 examples/second\n",
            "Test Loss=0.3688, Test acc=0.8835\n",
            "Files already downloaded and verified\n",
            "Test Loss=0.3636, Test accuracy=0.8846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define quantized model and load weight\n",
        "Nbits = 2 #Change this value to finish (d)\n",
        "\n",
        "net_2B = ResNetCIFAR(num_layers=20, Nbits=Nbits)\n",
        "net_2B= net_2B.to(device)\n",
        "net_2B.load_state_dict(torch.load(\"net_after_global_iterative_prune.pt\"))\n",
        "test(net_2B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0fLj0dyHUog",
        "outputId": "0f640d67-b6ec-4b08-99e1-19495ddb39e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=7358.1566, Test accuracy=0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized model finetuning\n",
        "finetune(net_2B, epochs=20, batch_size=256, lr=0.002, reg=1e-4)\n",
        "\n",
        "# Load the model with best accuracy\n",
        "net_2B.load_state_dict(torch.load(\"quantized_net_after_finetune.pt\"))\n",
        "test(net_2B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbB4yRosHcbP",
        "outputId": "50468988-c3be-4379-a659-37f9913a0f99"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 0\n",
            "[Step=50]\tLoss=2.2657\tacc=0.1443\t1161.9 examples/second\n",
            "[Step=100]\tLoss=2.2269\tacc=0.1528\t2233.3 examples/second\n",
            "[Step=150]\tLoss=2.2026\tacc=0.1613\t1692.3 examples/second\n",
            "Test Loss=2.1293, Test acc=0.1851\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\n",
            "[Step=200]\tLoss=2.1619\tacc=0.1895\t1037.5 examples/second\n",
            "[Step=250]\tLoss=2.1256\tacc=0.1945\t1897.9 examples/second\n",
            "[Step=300]\tLoss=2.1206\tacc=0.2029\t2195.4 examples/second\n",
            "[Step=350]\tLoss=2.1141\tacc=0.2072\t1714.3 examples/second\n",
            "Test Loss=2.1030, Test acc=0.2227\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "[Step=400]\tLoss=2.0908\tacc=0.2212\t907.9 examples/second\n",
            "[Step=450]\tLoss=2.0843\tacc=0.2302\t2320.9 examples/second\n",
            "[Step=500]\tLoss=2.0780\tacc=0.2317\t1841.8 examples/second\n",
            "[Step=550]\tLoss=2.0735\tacc=0.2346\t1999.6 examples/second\n",
            "Test Loss=2.0748, Test acc=0.2330\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "[Step=600]\tLoss=2.0606\tacc=0.2461\t978.6 examples/second\n",
            "[Step=650]\tLoss=2.0484\tacc=0.2471\t2377.8 examples/second\n",
            "[Step=700]\tLoss=2.0435\tacc=0.2467\t1628.5 examples/second\n",
            "[Step=750]\tLoss=2.0414\tacc=0.2484\t2272.4 examples/second\n",
            "Test Loss=2.0560, Test acc=0.2476\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "[Step=800]\tLoss=2.0380\tacc=0.2405\t982.5 examples/second\n",
            "[Step=850]\tLoss=2.0237\tacc=0.2539\t2336.3 examples/second\n",
            "[Step=900]\tLoss=2.0197\tacc=0.2574\t1634.5 examples/second\n",
            "[Step=950]\tLoss=2.0169\tacc=0.2587\t2380.0 examples/second\n",
            "Test Loss=2.0092, Test acc=0.2651\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "[Step=1000]\tLoss=2.0102\tacc=0.2633\t990.4 examples/second\n",
            "[Step=1050]\tLoss=2.0111\tacc=0.2617\t2173.8 examples/second\n",
            "[Step=1100]\tLoss=2.0055\tacc=0.2631\t1729.5 examples/second\n",
            "[Step=1150]\tLoss=2.0028\tacc=0.2634\t2441.5 examples/second\n",
            "Test Loss=2.0561, Test acc=0.2499\n",
            "\n",
            "Epoch: 6\n",
            "[Step=1200]\tLoss=1.9906\tacc=0.2759\t965.4 examples/second\n",
            "[Step=1250]\tLoss=1.9853\tacc=0.2759\t1971.3 examples/second\n",
            "[Step=1300]\tLoss=1.9814\tacc=0.2750\t1862.5 examples/second\n",
            "[Step=1350]\tLoss=1.9798\tacc=0.2751\t2520.2 examples/second\n",
            "Test Loss=1.9754, Test acc=0.2666\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "[Step=1400]\tLoss=1.9773\tacc=0.2801\t945.0 examples/second\n",
            "[Step=1450]\tLoss=1.9685\tacc=0.2765\t1806.5 examples/second\n",
            "[Step=1500]\tLoss=1.9660\tacc=0.2779\t2074.2 examples/second\n",
            "[Step=1550]\tLoss=1.9600\tacc=0.2804\t2606.8 examples/second\n",
            "Test Loss=1.9552, Test acc=0.2723\n",
            "Saving...\n",
            "\n",
            "Epoch: 8\n",
            "[Step=1600]\tLoss=1.9561\tacc=0.2792\t923.4 examples/second\n",
            "[Step=1650]\tLoss=1.9429\tacc=0.2851\t1616.7 examples/second\n",
            "[Step=1700]\tLoss=1.9390\tacc=0.2873\t2330.6 examples/second\n",
            "[Step=1750]\tLoss=1.9384\tacc=0.2863\t2692.1 examples/second\n",
            "Test Loss=1.9351, Test acc=0.2932\n",
            "Saving...\n",
            "\n",
            "Epoch: 9\n",
            "[Step=1800]\tLoss=1.9279\tacc=0.2856\t978.5 examples/second\n",
            "[Step=1850]\tLoss=1.9197\tacc=0.2885\t1662.9 examples/second\n",
            "[Step=1900]\tLoss=1.9187\tacc=0.2923\t2353.4 examples/second\n",
            "[Step=1950]\tLoss=1.9163\tacc=0.2949\t2774.7 examples/second\n",
            "Test Loss=1.9355, Test acc=0.2862\n",
            "\n",
            "Epoch: 10\n",
            "[Step=2000]\tLoss=1.9085\tacc=0.2948\t949.4 examples/second\n",
            "[Step=2050]\tLoss=1.8956\tacc=0.2982\t1673.7 examples/second\n",
            "[Step=2100]\tLoss=1.8907\tacc=0.3009\t2374.8 examples/second\n",
            "[Step=2150]\tLoss=1.8881\tacc=0.3032\t2865.3 examples/second\n",
            "Test Loss=2.0005, Test acc=0.2889\n",
            "\n",
            "Epoch: 11\n",
            "[Step=2200]\tLoss=1.8801\tacc=0.3061\t951.2 examples/second\n",
            "[Step=2250]\tLoss=1.8783\tacc=0.3079\t1732.5 examples/second\n",
            "[Step=2300]\tLoss=1.8719\tacc=0.3110\t2379.8 examples/second\n",
            "[Step=2350]\tLoss=1.8688\tacc=0.3118\t2812.6 examples/second\n",
            "Test Loss=1.8554, Test acc=0.3111\n",
            "Saving...\n",
            "\n",
            "Epoch: 12\n",
            "[Step=2400]\tLoss=1.8608\tacc=0.3110\t900.4 examples/second\n",
            "[Step=2450]\tLoss=1.8510\tacc=0.3162\t1876.4 examples/second\n",
            "[Step=2500]\tLoss=1.8434\tacc=0.3158\t2337.7 examples/second\n",
            "Test Loss=1.8377, Test acc=0.3272\n",
            "Saving...\n",
            "\n",
            "Epoch: 13\n",
            "[Step=2550]\tLoss=1.8368\tacc=0.3398\t1064.3 examples/second\n",
            "[Step=2600]\tLoss=1.8202\tacc=0.3210\t1763.4 examples/second\n",
            "[Step=2650]\tLoss=1.8176\tacc=0.3246\t1938.2 examples/second\n",
            "[Step=2700]\tLoss=1.8177\tacc=0.3246\t2372.1 examples/second\n",
            "Test Loss=1.8222, Test acc=0.3225\n",
            "\n",
            "Epoch: 14\n",
            "[Step=2750]\tLoss=1.7866\tacc=0.3177\t1058.8 examples/second\n",
            "[Step=2800]\tLoss=1.7921\tacc=0.3336\t1805.0 examples/second\n",
            "[Step=2850]\tLoss=1.7830\tacc=0.3368\t1993.1 examples/second\n",
            "[Step=2900]\tLoss=1.7819\tacc=0.3383\t2383.3 examples/second\n",
            "Test Loss=1.7843, Test acc=0.3314\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "[Step=2950]\tLoss=1.7655\tacc=0.3434\t1012.0 examples/second\n",
            "[Step=3000]\tLoss=1.7607\tacc=0.3498\t1756.4 examples/second\n",
            "[Step=3050]\tLoss=1.7534\tacc=0.3520\t2133.0 examples/second\n",
            "[Step=3100]\tLoss=1.7519\tacc=0.3517\t2227.0 examples/second\n",
            "Test Loss=1.8066, Test acc=0.3329\n",
            "Saving...\n",
            "\n",
            "Epoch: 16\n",
            "[Step=3150]\tLoss=1.7253\tacc=0.3544\t1030.8 examples/second\n",
            "[Step=3200]\tLoss=1.7285\tacc=0.3544\t1725.5 examples/second\n",
            "[Step=3250]\tLoss=1.7241\tacc=0.3579\t2156.6 examples/second\n",
            "[Step=3300]\tLoss=1.7192\tacc=0.3588\t2225.6 examples/second\n",
            "Test Loss=1.7742, Test acc=0.3421\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "[Step=3350]\tLoss=1.7247\tacc=0.3479\t1048.7 examples/second\n",
            "[Step=3400]\tLoss=1.7047\tacc=0.3668\t1697.7 examples/second\n",
            "[Step=3450]\tLoss=1.7018\tacc=0.3670\t2147.4 examples/second\n",
            "[Step=3500]\tLoss=1.6980\tacc=0.3672\t2118.0 examples/second\n",
            "Test Loss=1.6954, Test acc=0.3702\n",
            "Saving...\n",
            "\n",
            "Epoch: 18\n",
            "[Step=3550]\tLoss=1.6943\tacc=0.3681\t1059.4 examples/second\n",
            "[Step=3600]\tLoss=1.6873\tacc=0.3721\t1682.2 examples/second\n",
            "[Step=3650]\tLoss=1.6767\tacc=0.3749\t2294.0 examples/second\n",
            "[Step=3700]\tLoss=1.6717\tacc=0.3776\t2280.1 examples/second\n",
            "Test Loss=1.7121, Test acc=0.3528\n",
            "\n",
            "Epoch: 19\n",
            "[Step=3750]\tLoss=1.6440\tacc=0.3839\t1038.3 examples/second\n",
            "[Step=3800]\tLoss=1.6481\tacc=0.3830\t1688.8 examples/second\n",
            "[Step=3850]\tLoss=1.6574\tacc=0.3801\t2215.2 examples/second\n",
            "[Step=3900]\tLoss=1.6502\tacc=0.3848\t2313.3 examples/second\n",
            "Test Loss=1.6763, Test acc=0.3778\n",
            "Saving...\n",
            "Files already downloaded and verified\n",
            "Test Loss=1.6763, Test accuracy=0.3778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsObufR28vQ9"
      },
      "source": [
        "### Lab3 (e) Symmetric quantization\n",
        "#### Implement symmetric quantization in FP_layers.py, and repeat the process in (b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 6 #Change this value to finish (b) and (c)\n",
        "\n",
        "\n",
        "net = ResNetCIFAR(num_layers=20, Nbits=Nbits,symmetric=True)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEQbonng9UzW",
        "outputId": "ba3c47d0-4b61-4940-a6ae-054ab0c5ef63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3276, Test accuracy=0.9124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a4Ejq_sI8vQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dab0f6-1def-4b4f-8ea3-55c710b1aca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3520, Test accuracy=0.9083\n"
          ]
        }
      ],
      "source": [
        "Nbits = 5 #Change this value to finish (b) and (c)\n",
        "\n",
        "\n",
        "net = ResNetCIFAR(num_layers=20, Nbits=Nbits,symmetric=True)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 4 #Change this value to finish (b) and (c)\n",
        "\n",
        "\n",
        "net = ResNetCIFAR(num_layers=20, Nbits=Nbits,symmetric=True)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMdWrXNrLQaj",
        "outputId": "b9aef464-d2b5-4e1d-ec0f-e08639f6f18e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.4227, Test accuracy=0.8875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 3#Change this value to finish (b) and (c)\n",
        "\n",
        "\n",
        "net = ResNetCIFAR(num_layers=20, Nbits=Nbits,symmetric=True)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxUy3Rf-LTOF",
        "outputId": "8da5668f-ec9f-4361-f717-94af83587fcb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=2.3739, Test accuracy=0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbits = 2 #Change this value to finish (b) and (c)\n",
        "\n",
        "\n",
        "net = ResNetCIFAR(num_layers=20, Nbits=Nbits,symmetric=True)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pwJ9seqLWHS",
        "outputId": "1f676568-994e-48f3-d0a3-f08362296437"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=42.7781, Test accuracy=0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mg_yRvNyLZGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}